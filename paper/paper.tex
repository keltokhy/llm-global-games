\documentclass[10pt,twocolumn]{article}
\usepackage{amssymb,amsmath,amsthm}
\usepackage[margin=0.75in]{geometry}
\usepackage{microtype}
\usepackage[hidelinks]{hyperref}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{float}
\usepackage{placeins}
\usepackage[round]{natbib}
\usepackage{xcolor}
\usepackage{subcaption}
\usepackage{multirow}
% tablenotes environment (lightweight replacement for threeparttable)
\newenvironment{tablenotes}{\par\vspace{2pt}\noindent\begin{minipage}{\linewidth}}{\end{minipage}}

\newtheorem{proposition}{Proposition}
\newtheorem{hypothesis}{Hypothesis}
\newtheorem{result}{Result}

\urlstyle{same}
\interfootnotelinepenalty=10000

% Allow LaTeX to place floats near their source instead of deferring to end
\renewcommand{\topfraction}{0.9}
\renewcommand{\bottomfraction}{0.8}
\renewcommand{\textfraction}{0.1}
\renewcommand{\floatpagefraction}{0.7}
\renewcommand{\dbltopfraction}{0.9}
\renewcommand{\dblfloatpagefraction}{0.7}
\setcounter{topnumber}{4}
\setcounter{bottomnumber}{4}
\setcounter{totalnumber}{8}
\setcounter{dbltopnumber}{4}

\title{LLMs Can Play (Global) Games}

\author{
  Khaled Eltokhy \\
  Department of Economics \\
  The Graduate Center, CUNY
}
\date{February 2026}

\begin{document}

\input{tables/stats_macros.tex}

\maketitle

\begin{abstract}
I embed eight large language models in the Morris--Shin (2003) regime change game, conveying private signals as natural-language intelligence briefings. Across 1,700 country--periods (42,500 individual decisions), join rates exhibit monotone threshold behavior consistent with the equilibrium comparative statics (mean $r = +0.74$, $p < 0.001$ for every model); scrambling briefings collapses the within-country correlation ($r = +0.07$) and inverting signals flips it ($r = -0.69$). Taking this as a platform, I study how authoritarian regimes exploit the same information channel that makes coordination possible. Communication introduces strategic uncertainty without raising coordination: the pooled effect on join rates is small and not statistically significant, yet the channel it opens is exploitable. Surveillance poisons the channel through preference falsification---agents maintain private beliefs but self-censor, pushing join rates well below the communication baseline ($-11.1$~pp on average across three architectures). Censorship pools and distorts private signals, and propaganda saturates quickly. The regime does not need to change what citizens believe; it needs only to make them uncertain about each other. These results have implications for AI alignment: LLMs exhibit emergent preference falsification---strategically misrepresenting expressed preferences under observation---without explicit training for deceptive behavior, and form belief-like internal states that fully mediate the signal-to-action pathway.
\end{abstract}

\medskip
\noindent\textbf{JEL:} C72, C92, D82, D83, P16 \\
\noindent\textbf{Keywords:} global games, regime change, LLM agents, information design, Bayesian persuasion, preference falsification, AI alignment, emergent capabilities


%% ============================================================
%% 1. INTRODUCTION
%% ============================================================
\section{Introduction}

Coordination games with multiple equilibria are central to the analysis of bank runs \citep{diamond1983}, currency attacks \citep{obstfeld1996}, and political upheaval \citep{angeletos2007a}. The theory of global games \citep{carlsson1993, morris2003, frankel03} resolves the multiplicity by introducing private information: when agents observe noisy private signals about an underlying fundamental, a unique equilibrium emerges in threshold strategies. The canonical application---regime change---has been extensively studied theoretically. Laboratory experiments have tested the theory in simplified settings: small groups with numeric signals and stylized payoffs \citep{heinemann2004, heinemann2009, szkup2020}. But the full Morris--Shin regime change game---continuous private signals, large groups, strategic uncertainty---has not been implemented experimentally. Field data from actual crises confounds strategic behavior with institutional and informational heterogeneity.

I take a different approach: I embed large language model (LLM) agents directly in the \citet{morris2003} regime change game. Each agent receives a private signal $x_i = \theta + \varepsilon_i$, translated into a natural-language intelligence briefing describing the political, economic, and security situation. No explicit payoff table is provided---the stakes of joining or staying are embedded in the narrative, forcing agents to extract strategic information from language rather than from a formatted matrix. I run this experiment across eight architecturally distinct models spanning six families (Mistral, Llama, Qwen, GPT, Arcee, and MiniMax), with 25 agents per country--period and pure-treatment sample sizes of 100--800 country--periods per model (Table~\ref{tab:models}), totaling 1,700 country--periods (42,500 individual decisions) in the pure treatment alone.

The first finding is that LLM agents exhibit stable, monotone threshold behavior consistent with the equilibrium prediction. The correlation between the theoretical attack mass $A(\theta) = \Phi[(x^* - \theta)/\sigma]$ and the empirical join fraction averages $r = +0.74$ ($p < 0.001$ for every model). Two falsification tests confirm that this correlation is driven by briefing content rather than incidental features of the prompt: randomly scrambling briefings across periods reduces the within-country correlation to $r = +0.07$, and inverting the signal direction flips it to $r = -0.69$. In both cases the change relative to the pure treatment is significant (Fisher $z$-test, $p < 0.001$). This establishes monotonicity and content sensitivity---necessary conditions for equilibrium play, though not sufficient to establish full Bayesian Nash rationality. Elicited beliefs track the Bayesian posterior ($r = +0.79$) and predict actions beyond what signals alone predict ($r = +0.84$, exceeding the text-baseline $r = 0.80$), providing evidence of strategic processing beyond mere sentiment following.

The second finding---and the paper's central contribution---is that the information channel is simultaneously the mechanism of coordination and its greatest vulnerability. Pre-play communication does not raise agents' beliefs or their willingness to act (mean effect \CommDeltaPPModelAvg~pp across models; not significant in the pooled sample), yet the channel it opens introduces strategic uncertainty that makes coordination exploitable. Surveillance poisons the channel through preference falsification ($-13.4$~pp for the primary model, $p < 0.001$). Censorship pools and distorts private signals, and its interaction with surveillance is large and model-dependent. Propaganda's behavioral effect saturates quickly while its mechanical effect scales linearly, implying diminishing returns. The regime does not need to change what citizens believe---it needs only to make them uncertain about each other.

The paper makes three contributions. First, it tests whether the threshold equilibrium patterns predicted by global games theory emerge when LLM agents are embedded in the full Morris--Shin regime change game---with continuous private signals, large groups, and narrative information---going beyond the simplified coordination games tested in existing laboratory experiments. Second, it provides the first experimental tests of information design and authoritarian control predictions from \citet{goldstein2016}, \citet{kolotilin2022}, and \citet{edmond2013} in a coordination game, yielding a unified account of how authoritarian regimes exploit the dual nature of communication channels---instruments of coordination that are simultaneously vectors of control. Third, it demonstrates that LLMs can serve as experimental subjects for strategic environments, extending the \citet{horton2023} \textit{homo silicus} methodology beyond $2 \times 2$ games to the continuous-signal, $N$-player coordination games that dominate applied theory, with results replicating across eight architecturally distinct models. A corollary for AI alignment: strategic behavior including preference falsification emerges from pretraining on human text about strategic interaction, without explicit optimization for deception, and is robust across architectures spanning 3B to 235B parameters---suggesting that deception-adjacent capabilities are a convergent property of training on sufficient strategic reasoning data.

Section~\ref{sec:literature} reviews the related literature. Section~\ref{sec:model} presents the theoretical framework. Section~\ref{sec:design} describes the experimental design. Section~\ref{sec:results} reports the main results on equilibrium alignment; Section~\ref{sec:falsification} presents the falsification tests. Section~\ref{sec:communication} analyzes pre-play communication. Sections~\ref{sec:infodesign}--\ref{sec:interactions} cover information design, surveillance, propaganda, and their interactions. Appendix~\ref{sec:robustness} reports robustness checks. Section~\ref{sec:conclusion} concludes.


%% ============================================================
%% 2. RELATED LITERATURE
%% ============================================================
\section{Related Literature} \label{sec:literature}

This paper connects five literatures: global games and equilibrium selection, information design and Bayesian persuasion, communication in coordination games, the political economy of authoritarian information control, and the emerging field of LLMs as economic agents.

The theory of global games resolves the equilibrium multiplicity that plagues coordination games by introducing heterogeneous private information. \citet{carlsson1993} showed that adding arbitrarily small noise to a 2$\times$2 coordination game generically selects the risk-dominant equilibrium via iterated dominance. \citet{morris1998} applied this technique to currency crises, demonstrating that heterogeneous private signals about fundamentals deliver a unique threshold equilibrium even in large-player coordination games. \citet{frankel03} generalized the result to $N$-player, multi-action games with strategic complementarities.

The canonical regime change application---in which citizens decide whether to join an uprising against a regime of uncertain strength---was developed by \citet{morris2003}, who established the threshold equilibrium structure I implement experimentally. \citet{angeletos2007a} extended the framework to dynamic settings where agents learn across periods, showing that multiplicity can re-emerge when agents observe whether the regime survived previous rounds. \citet{morris2002} demonstrated that public signals are overweighted in coordination games because they predict others' actions, a finding central to my communication and information design treatments.

Laboratory experiments have tested the theory in stylized settings that necessarily depart from the canonical regime change game. \citet{heinemann2004} ran coordination games with public and private signals, finding that subjects' thresholds match the global game prediction under private information but tilt toward payoff-dominance under common information. \citet{heinemann2009} measured strategic uncertainty directly through certainty equivalents. \citet{shurchkov2013} tested dynamic global games, finding that subjects learn from failed attacks. \citet{szkup2020} elicited beliefs alongside actions, finding that comparative statics of thresholds with respect to signal precision are reversed relative to theory---subjects become more cautious with noisier signals, consistent with level-$k$ thinking rather than Bayesian Nash equilibrium. \citet{helland2021} tested information quality in a regime change game with numeric signals and small groups, confirming the level-$k$ reversal. These experiments share a common limitation: subjects receive numeric signal draws and face stylized payoff tables, compressing the rich information processing that real-world coordination requires into a simple decision problem.

This paper implements the full Morris--Shin regime change game with natural-language private signals and 25-agent groups, going beyond the small-group, numeric-signal designs of existing experiments to test the threshold equilibrium prediction in the canonical application for which it was developed.

\citet{kamenica2011} established the Bayesian persuasion framework: a sender who commits to an information structure can influence a Bayesian receiver's action by shaping the posterior distribution of beliefs. \citet{bergemann2016} unified Bayesian persuasion with correlated equilibrium under the concept of Bayes Correlated Equilibrium. \citet{bergemann2019information} provided a comprehensive survey integrating cheap talk, persuasion, and robust mechanism design.

The application to coordination games is directly relevant. \citet{goldstein2016} applied Bayesian persuasion to the regime change game, showing that a credible commitment to abandon the regime below a threshold functions as an optimal signal. \citet{inostroza2025} solved the optimal public information design problem in a global game with heterogeneous private signals, characterizing when pass/fail structures are optimal. \citet{kolotilin2022} characterized optimal censorship via one-sided pooling rules (``upper censorship'' in their terminology), showing that pooling one side of a threshold can be optimal for all priors when the sender's marginal utility is quasi-concave. \citet{mathevet2020} characterized the extent to which an information designer can manipulate agents' higher-order beliefs.

My information design experiments implement these theoretical designs computationally within a full-scale coordination game, providing the first experimental test of information design predictions in a global game.

The cheap talk literature---\citet{crawford1982}, \citet{farrell1996}, \citet{blume2007}, \citet{ellingsen2010}---establishes that pre-play communication can improve coordination, with \citet{avoyan2020} testing this in a two-player global game. In real-world coordination, \citet{enikolopov2020} provided causal evidence that social media penetration increases protest incidence. My communication treatment embeds agents in a Watts-Strogatz small-world network and allows natural-language messaging before the coordination decision.

The theoretical literature on authoritarian information control builds directly on the global games framework. \citet{edmond2013} embedded costly propaganda into the Morris--Shin regime change game. \citet{kuran1991} provides the foundational theory of preference falsification---the systematic misrepresentation of political preferences under social pressure. Empirical work documents that Chinese censorship targets content with collective action potential \citep{king2013}, that surveillance awareness suppresses expression \citep{penney2016, stoycheff2016}, and that pro-regime propaganda reduces protest probability \citep{carter2021}. My surveillance and propaganda treatments directly test these mechanisms within the full regime change game---an environment difficult to implement with human subjects at scale.

\citet{horton2023} proposed treating LLMs as ``homo silicus''---computational models of human decision-makers. Subsequent work has tested LLMs in game-theoretic settings: \citet{akata2025} found that LLMs perform well in self-interested games but struggle in coordination games; \citet{petrov2025} evaluated 22 LLMs on a behavioral game theory battery, finding that model scale alone does not predict strategic performance; \citet{sun2025survey} identify coordination games as a consistent failure mode. The alignment literature motivates my design: \citet{huang2024} and \citet{carlini2025} document that ethical alignment and chatbot fine-tuning shift risk preferences and amplify omission bias, which is why I convey strategic stakes through narrative rather than explicit payoff tables. Critical reviews by \citet{gao2025} and \citet{grossmann2025} warn that validation remains poorly addressed in LLM-based agent simulations.

No existing paper places LLM agents in a Morris--Shin global game---the specific game form where private noisy signals about an underlying state variable determine a threshold equilibrium. I provide the first such implementation, and extend it to information design, surveillance, and propaganda.


%% ============================================================
%% 3. THEORETICAL FRAMEWORK
%% ============================================================
\section{The Global Game of Regime Change} \label{sec:model}

A continuum of citizens indexed by $i \in [0,1]$ simultaneously choose whether to join an uprising ($a_i = 1$) or stay home ($a_i = 0$). The regime has strength $\theta \in \mathbb{R}$, drawn from a diffuse (improper uniform) prior. States $\theta \leq 0$ represent regimes so weak they fall without opposition; states $\theta \geq 1$ represent regimes that survive even unanimous attack. The regime falls if the mass of citizens who join exceeds $\theta$:
\begin{equation}
    \text{Regime falls} \iff A \equiv \int_0^1 a_i \, di > \theta.
\end{equation}

Payoffs depend on the citizen's action and the outcome:
\begin{equation}
    u_i(a_i, A, \theta) = \begin{cases}
        B & \text{if } a_i = 1 \text{ and } A > \theta \\
        -C & \text{if } a_i = 1 \text{ and } A \leq \theta \\
        0 & \text{if } a_i = 0
    \end{cases}
\end{equation}
where $B > 0$ is the payoff to joining a successful uprising and $C > 0$ is the cost of joining a failed attempt. Non-participants receive zero regardless of the outcome.

Each citizen observes a private signal $x_i = \theta + \varepsilon_i$, where $\varepsilon_i \sim \mathcal{N}(0, \sigma^2)$ independently across citizens.

\begin{proposition}[Morris and Shin, 2003]
In the limit of diffuse priors, there exists a unique Bayesian Nash equilibrium in threshold strategies. An agent joins if and only if $x_i < x^*$, where
\begin{equation}
    x^* = \theta^* + \sigma \Phi^{-1}(\theta^*)
\end{equation}
and $\theta^* = B/(B+C)$.
\end{proposition}

The \textit{attack mass}---the fraction of the population that joins at regime strength $\theta$---is:
\begin{equation} \label{eq:attack_mass}
    A(\theta) = \Phi\!\left(\frac{x^* - \theta}{\sigma}\right).
\end{equation}

This is a decreasing function of $\theta$: weaker regimes face larger uprisings.

An information designer controls the mapping $\pi: \Theta \to \Delta(\mathcal{S})$ from states to signal distributions, but cannot control agents' actions. In my implementation, $\pi$ is the function mapping regime strength $\theta$ to the parameters of the briefing generator---a deterministic system that produces a natural-language intelligence briefing from a z-score derived from the agent's private signal.

The briefing generator has three control parameters: clarity (the width of the Gaussian kernel mapping z-scores to text, where wider kernels produce more ambiguous briefings), directional precision (the slope of the mapping from z-score to briefing sentiment, where steeper slopes produce more accurate signal reflection), and dissent framing (the floor on the probability that the briefing includes language about public discontent).

The designer concentrates manipulation near $\theta^*$ using a Gaussian proximity weight:
\begin{equation}
    w(\theta) = \exp\!\left(-\left(\frac{\theta - \theta^*}{\text{bandwidth}}\right)^2\right)
\end{equation}
where $\text{bandwidth} = 0.15$ in the baseline specification.

The framework generates testable predictions for both the baseline game and information design.

\begin{hypothesis}[Equilibrium Alignment] \label{hyp:alignment}
The empirical join fraction should be positively correlated with the theoretical attack mass $A(\theta)$.
\end{hypothesis}

\begin{hypothesis}[Signal Dependence] \label{hyp:scramble}
The correlation in Hypothesis~\ref{hyp:alignment} should collapse when the mapping from $\theta$ to briefing content is broken (scramble test).
\end{hypothesis}

\begin{hypothesis}[Signal Direction] \label{hyp:flip}
The correlation should invert when signals are flipped.
\end{hypothesis}

\begin{hypothesis}[Communication Effect] \label{hyp:comm}
Pre-play communication should increase join rates, with the effect strongest near $\theta^*$ where strategic uncertainty is highest.
\end{hypothesis}

\begin{hypothesis}[Stability Design] \label{hyp:stability}
Increasing ambiguity and mixed evidence near $\theta^*$ should flatten the $\theta$--join relationship and induce pooling.
\end{hypothesis}

\begin{hypothesis}[Upper Censorship] \label{hyp:censor}
Upper censorship should distort coordination by pooling weak-regime states to a neutral signal, flattening join rates in the censored region \citep{kolotilin2022}.
\end{hypothesis}

\begin{hypothesis}[Surveillance Chilling Effect] \label{hyp:surveillance}
Informing agents that communications are monitored should reduce coordination \citep{kuran1991}.
\end{hypothesis}

\begin{hypothesis}[Propaganda Dose-Response] \label{hyp:propaganda}
Regime plant agents transmitting pro-regime messages should suppress coordination, with the effect increasing in the number of plants \citep{edmond2013}.
\end{hypothesis}


%% ============================================================
%% 4. EXPERIMENTAL DESIGN
%% ============================================================
\section{Experimental Design} \label{sec:design}

The experiment has three parts. Part~I tests whether LLM agents play the global game: a pure treatment (private signals only), a communication treatment (pre-play messaging), and falsification tests. Part~II takes the behavioral foundation as given and studies information design: stability/instability designs, censorship, public signal injection, and single-channel decomposition. Part~III tests whether an authoritarian regime can exploit the communication channel through surveillance, propaganda, and their interaction. All LLM interactions use the same prompt structure across models.

For each country--period, nature draws $\theta \sim \mathcal{N}(\bar{z}, 1)$, where $\bar{z}$ is a public prior mean drawn randomly for each country. Each agent $i$ receives a private signal $x_i = \theta + \varepsilon_i$ and computes a z-score $z_i = (x_i - \bar{z})/\sigma$. Because agents observe only their private briefing and never the prior distribution or its parameters, the diffuse-prior equilibrium formula (Proposition~1) serves as the relevant benchmark. The z-score is then translated into a multi-paragraph intelligence briefing by a deterministic generator that maps signal strength to narrative content about regime stability, economic conditions, public sentiment, and coordination prospects. Figure~\ref{fig:pipeline} summarizes the signal-to-text-to-decision pipeline.

\begin{figure*}[htbp]
  \centering
  \includegraphics[width=\textwidth]{figures/diagram_pipeline.pdf}
  \caption{Signal-to-text-to-decision pipeline. Regime strength $\theta$ generates private signals $x_i$, which are converted to z-scores and rendered into natural-language intelligence briefings via 8 evidence domains and 3 latent sliders (direction, clarity, coordination). Each LLM agent reads its briefing and outputs a binary JOIN/STAY decision. The briefing layer is deterministic conditional on $z_i$; all stochasticity enters through the LLM's decoding.}
  \label{fig:pipeline}
\end{figure*}

A design choice deserves explicit comment. The briefing generator maps z-scores to narrative content through logistic slider functions and graded phrase ladders, so briefings at low $\theta$ are designed to convey regime weakness and those at high $\theta$ regime strength. The monotone \textit{direction} of the response is therefore partially built into the text generation---any model that extracts sentiment from the narrative will produce a negative correlation between $\theta$ and join probability. The empirical contribution of the equilibrium alignment test is not the direction but the \textit{quantitative structure}: the sigmoid shape, the sensitivity of the fitted cutoff to payoff narratives (Section~\ref{sec:results}), and the robustness across eight architecturally distinct models spanning 3B to 235B parameters. The within-briefing falsification tests (Appendix~\ref{sec:within_scramble}) further confirm that the signal is distributed across all eight evidence domains rather than driven by any single formatting feature or domain subset.

The briefing rendering is calibrated once per model using a separate z-score sweep to ensure that join probability is monotone in $z$ and roughly centered near the cutoff. Calibration adjusts a single parameter---the cutoff center---via a damped iterative procedure that shifts the center until the fitted logistic is approximately zero-centered. The sigmoid shape (its slope and curvature) is emergent from the LLM's own response pattern and is never optimized or penalized. Holdout validation (30\% of z-grid points withheld) suggests no overfitting: holdout RMSE (0.112) is comparable to training RMSE (0.131). Calibration does not use $\theta$ draws or any global-game outcome data, and all reported treatments and falsification tests hold calibrated parameters fixed. Importantly, calibration centers the response function but does not create it: a model that produced random or flat responses to briefing content would show no monotone pattern regardless of calibration. The sigmoid shape and its slope are emergent properties of the model's language understanding. The appendix confirms this directly: three architecturally distinct models run with default parameters (no calibration) produce $|r| > 0.85$, establishing that the monotone threshold pattern is emergent rather than calibrated (Appendix Table~\ref{tab:uncalibrated}).

Each agent receives a system prompt identifying them as a citizen deciding whether to JOIN or STAY, followed by their intelligence briefing. No explicit payoff table is provided---the stakes are conveyed entirely through the narrative.

This design choice is substantive. In preliminary experiments, providing an explicit payoff table caused sophisticated models to short-circuit the information-processing channel: they computed the optimal strategy from the table and ignored briefing content, producing flat join rates uncorrelated with regime strength. The no-payoff-table design forces agents to form beliefs from the narrative, mirroring how real citizens process political information from news and rumors rather than from a formatted decision matrix.

Part~I has four treatments. In the \textit{pure global game}, each agent decides independently based on their private briefing. In the \textit{communication} treatment, agents send a message to a small network of ``trusted contacts'' (Watts-Strogatz small-world network, $k=4$, $p=0.3$) before deciding, with access to both their briefing and received messages. Two falsification tests break the signal channel: in \textit{scramble}, all briefings across periods within a country are pooled and randomly redistributed; in \textit{flip}, the z-score is negated before briefing generation, so agents who should see weak-regime cues receive strong-regime cues and vice versa.

Part~II implements information designs. Design names refer to the \textit{regime's} objective, not the equilibrium outcome: the ``stability'' design is the information structure a stability-seeking regime would implement. The \textit{stability-maximizing} design multiplies clarity width by 4, raises the dissent floor to 0.45, and flattens the directional slope by a factor of 0.25 near $\theta^*$. The \textit{instability-maximizing} design does the opposite: clarity width is multiplied by 0.15, the dissent floor is lowered to 0.05, and the directional slope is steepened by a factor of 3. \textit{Public signal injection} appends a shared ``news bulletin'' generated from $\theta$ with 4 observations to each agent's private briefing, creating a common-knowledge channel. \textit{Upper censorship} pools weak-regime states ($\theta \le \theta^*$) so agents receive an identical censored briefing, while fully revealing states above $\theta^*$ \citep{kolotilin2022}; \textit{lower censorship} pools strong-regime states ($\theta \ge \theta^*$).

Part~III tests authoritarian instruments that exploit the communication channel. The \textit{surveillance} treatment augments the communication prompt with a warning that communications are being monitored by regime security services. \textit{Propaganda} introduces regime plant agents ($k = 2, 5, 10$) who participate in the communication network but transmit fixed pro-regime messages and always STAY.

\input{tables/tab_models.tex}

I test eight architecturally distinct models spanning six architecture families (Table~\ref{tab:models}). Models range from 3 billion to 235 billion parameters, including both dense architectures (Llama, Mistral) and mixture-of-experts (Qwen). All experiments use $N = 25$ agents per country--period and $\sigma = 0.3$, with sample sizes varying by model and treatment as reported in Table~\ref{tab:models}. I vary $B$ and $C$ such that $\theta^* = B/(B+C)$ has a mean of approximately 0.45 across periods. All LLM calls use temperature $= 0.7$ with a single sample per decision---no majority voting or averaging---so each of the 42,500 individual decisions reflects one stochastic draw from the model's conditional distribution (see Appendix~\ref{sec:decoding} for full decoding parameters).

For the information design experiments, I fix $B = C = 1$ (so $\theta^* = 0.50$) and a grid of 9 values of $\theta$ spanning $[\theta^* - 0.30, \theta^* + 0.30] = [0.20, 0.80]$, running repeated country--periods per $(\text{design}, \theta)$ cell with 25 agents each. Baseline, stability, censorship, scramble, and flip use 30 repetitions per cell (270 observations per design). Instability and public signal use 60 repetitions per cell (540 observations). Single-channel decomposition uses 10 repetitions per cell (90 observations) for each channel. The primary model is Mistral Small Creative. Cross-model replication uses five additional models.

Table~\ref{tab:treatment_map} maps each treatment to the theoretical channel it tests, the directional prediction, and the observed result.

\input{tables/tab_treatment_map.tex}

The eight hypotheses in Section~\ref{sec:model} were pre-specified; all achieve $p < 0.001$ individually and survive Bonferroni correction at $\alpha = 0.05/8 = 0.00625$. Exploratory analyses---decomposition, cross-model heterogeneity, and instrument interactions---are reported with uncorrected $p$-values and should be interpreted accordingly.

%% ============================================================
%% 5. RESULTS: PURE GLOBAL GAME
%% ============================================================
\section{Do LLM Agents Play the Global Game?} \label{sec:results}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\columnwidth]{figures/fig01_sigmoid.pdf}
  \caption{Empirical join fraction vs.\ regime strength $\theta$ (Mistral Small Creative, 800 country--periods). Grey points show binned means with 95\% CIs; solid line is the fitted logistic. Dashed red: theoretical attack mass $A(\theta)$. The empirical sigmoid is shifted leftward ($\hat{\theta}^* = -0.33$) relative to the theoretical threshold ($\theta^* = 0.50$), reflecting the attenuation and baseline action bias discussed in the text. Cross-model results in Table~\ref{tab:main_results} (mean $r = +0.74$, all eight significant at $p < 0.001$).}
  \label{fig:sigmoid}
\end{figure}

\begin{result}[Equilibrium Alignment]
Across eight models and 1,700 country--periods in the pure global game treatment, the Pearson correlation between the empirical join fraction and the theoretical attack mass $A(\theta)$ averages $r = +0.74$ ($p < 0.001$ for every model).
\end{result}

Table~\ref{tab:main_results} reports results by model. Correlations range from $r = +0.66$ (MiniMax M2-Her) to $r = +0.84$ (Trinity Large), with the pooled correlation at $r = +0.70$---lower than most individual models' because heterogeneous mean join rates across models add noise when pooling. The pooled OLS regression yields:
\begin{equation}
    J = 0.14 + 0.54\,A(\theta), \quad R^2 = 0.49.
\end{equation}

The slope of 0.54 indicates that LLM agents respond to the theoretical attack mass at roughly half the predicted rate---an attenuation expected when agents process narrative rather than numeric signals, since the briefing-to-belief mapping introduces noise that biases the slope toward zero (classical measurement error attenuation). The intercept of 0.14 reflects a baseline propensity to join even when the equilibrium predicts near-zero participation.\footnote{Country-period observations within a model share calibration parameters and prompt structure, raising the possibility that standard errors understate uncertainty. The homoskedastic SE on the OLS slope is 0.014; HC1 (heteroskedasticity-robust) yields 0.013. Clustering by country inflates the SE to 0.049 but preserves significance ($p < 10^{-25}$). Clustering by model yields SE $= 0.021$ ($p < 10^{-55}$). All eight per-model correlations remain significant at $p < 0.001$ under country-clustered inference.}

\input{tables/tab_main_results.tex}

The mean join rate across all models is 0.44, close to the theoretical mean.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\columnwidth]{figures/fig02_cross_model.pdf}
  \caption{Cross-model summary of signal monotonicity. Points report $|r(\theta,\ \mathrm{join})|$ under pure and communication; $x$ markers (if any) indicate models where scrambling does not collapse the correlation ($|r|>0.3$).}
  \label{fig:cross_model}
\end{figure}

The alignment is stable across architectures: correlations span $r \in [0.66, 0.84]$ despite parameter counts ranging from 3B to 235B (Table~\ref{tab:main_results}). Mean join rates vary---from 0.38 (Mistral) to 0.50 (Qwen3 30B)---reflecting model-specific action biases that shift the intercept but not the slope or correlation. In the language of the global games model, different LLMs implement different cutoff strategies, but all respond monotonically to the underlying signal.

\input{tables/tab_logistic_params.tex}

Table~\ref{tab:logistic_params} reports logistic fit parameters---estimated cutoff $\hat{\theta}^*$ and slope $\beta$---for each model under both pure and communication treatments. Most models have estimated cutoffs near the theoretical $\theta^* \approx 0.45$, with slopes ranging from 0.6 (MiniMax) to 3.6 (Llama under communication). Communication consistently steepens the logistic ($\beta_{\text{comm}} > \beta_{\text{pure}}$ for all eight models), suggesting that messages sharpen rather than blur the signal, even though the net effect on join rates is small.

The positive correlation with $A(\theta)$ confirms that LLM behavior is monotone in the signal and sensitive to briefing content---necessary conditions for equilibrium play. Whether this reflects full Bayesian Nash rationality or a simpler heuristic that happens to track the equilibrium prediction is a harder question. The LLM's join curve is substantially steeper than a naive text-sentiment predictor (logistic slope 1.78 vs.\ the gradual text baseline; $r = 0.80$), suggesting processing beyond surface sentiment (Section~\ref{sec:falsification}). The scramble and flip tests confirm that the correlation is driven by content, not by incidental features of the prompt. Belief elicitation reveals that agents form expectations tracking the Bayesian posterior ($r = +0.79$) and predict actions beyond what signals alone explain (partial $r = +0.93$), consistent with strategic reasoning about others' likely behavior. I use ``equilibrium alignment'' as shorthand for this behavioral pattern throughout, without claiming that agents compute or approximate the Bayesian Nash equilibrium in the decision-theoretic sense.

\subsection*{Interpretation: What Equilibrium Alignment Means}

\textit{(a) What the correlation measures.} The Pearson $r$ between $J$ and $A(\theta)$ measures whether join rates track the monotone sigmoid shape predicted by global game theory---not just the direction, but the quantitative pattern across the full range of $\theta$. A model that randomly joins 50\% of the time, or that responds only to extreme signals, would not produce $r = +0.74$.

\textit{(b) What it does not establish.} Agents do not observe payoffs $(B, C)$, signal precision $\sigma$, or group size $N$---they process narrative without access to the mathematical objects defining the equilibrium. ``Equilibrium alignment'' denotes the behavioral pattern: join rates track the theoretical attack mass, respond monotonically to signal content, and collapse or invert under falsification. Whether this reflects approximate Bayesian reasoning, a learned heuristic, or training-data associations is an open question the design cannot resolve. For AI interpretability, the relevant observation is that these models form intermediate representations---elicited as beliefs---that fully mediate the signal-to-action pathway (Pseudo $R^2 = 0.975$; Table~\ref{tab:regressions}, Column~3). The raw signal adds no predictive power once beliefs are included, indicating that behavior is driven by an opaque internal state rather than a transparent input-output mapping.

\textit{(c) Supporting evidence for strategic reasoning over text classification.} Three results distinguish the pattern from mere sentiment extraction.

First, the cost/benefit test shifts the fitted cutoff in the direction predicted by payoff theory without disrupting the sigmoid shape (Table~\ref{tab:bc_statics}). Theory predicts that higher cost of failed action raises the equilibrium cutoff (less joining), while lower cost lowers it. The high-cost narrative (``severe reprisals---imprisonment, asset seizure, and retaliation against families'') drops mean joining to 19.0\% with cutoff $\hat{\theta}^* = 0.13$; the low-cost narrative (``minimal consequences---brief detentions at most'') raises it to 69.3\% with cutoff $\hat{\theta}^* = 0.72$; the baseline is 41.3\% with $\hat{\theta}^* = 0.39$. Crucially, $|r| > 0.85$ in all three conditions---only the location shifts, while the monotone structure is preserved. A pure text classifier would not systematically shift cutoffs in the direction predicted by payoff theory.

Second, belief elicitation shows beliefs track the Bayesian posterior ($r = +0.79$) and predict actions beyond what signals alone explain (partial $r = +0.93$), consistent with strategic inference about others' likely behavior.

Third, construct validity: a three-feature model (direction, clarity, coordination) outperforms a one-feature sentiment baseline, indicating processing beyond surface tone.

The correlation is also invariant to LLM decoding temperature ($r \in [-0.88, -0.87]$ across $T \in \{0.3, 0.7, 1.0\}$; Appendix~\ref{sec:temp_robustness}). What matters for the information design experiments in Parts~II and~III is that the behavioral regularity---monotone signal response---is robust enough to serve as a platform for studying how information structures shift coordination outcomes.

\input{tables/tab_bc_statics.tex}

\textit{Notation convention.} Part~I reports $r(J, A(\theta))$, which is positive because both the attack mass and join fraction decrease in $\theta$. Parts~II and~III (Section~\ref{sec:infodesign} onward) use a fixed $\theta$-grid and report $r(J, \theta)$ directly, which is \textit{negative} under alignment. The sign change reflects the convention, not a behavioral reversal.


%% ============================================================
%% 6. FALSIFICATION
%% ============================================================
\section{Falsification Tests} \label{sec:falsification}

The positive correlation documented in Section~\ref{sec:results} admits an alternative explanation: LLM agents might simply produce stereotyped responses that happen to correlate with regime strength for reasons unrelated to the briefing content. The scramble and flip tests discriminate between this alternative and genuine signal extraction.

\begin{result}[Signal Dependence]
Cross-period scrambling of briefings reduces the mean within-country correlation from $r = +0.74$ to $r = +0.07$ across seven models. The pooled within-country correlation drops from $r = +0.70$ to $r = +0.04$ (Fisher $z = 21.22$, $p < 0.001$).
\end{result}

The scramble preserves the marginal distribution of briefing content but breaks the mapping from each period's $\theta$ to the signals agents receive. It thus serves as a format-preserving null: text length, vocabulary, domain coverage, and narrative structure are held constant---only the informational mapping from regime strength to agent signal is severed. Because the cross-period permutation operates within countries, the raw pooled correlation includes a between-country ecological confound (countries with different $\theta$ distributions produce spurious correlation even after scrambling). All scramble correlations therefore use within-country (country-demeaned) Pearson $r$, which isolates the signal-to-outcome link that the falsification test is designed to assess. The collapse in the demeaned correlations ($+0.07$ mean, $+0.04$ pooled) rules out the possibility that baseline alignment is primarily driven by prompt aesthetics or surface formatting rather than content extraction. The flip test provides a stronger check: every model shows clear sign reversal, confirming that all models respond to the directional content of the briefing.

\begin{result}[Signal Direction]
Inverting the signal direction flips the mean correlation from $r = +0.74$ to $r = -0.69$ across seven models. The pooled correlation moves from $r = +0.70$ to $r = -0.66$ (Fisher $z = 42.67$, $p < 0.001$).
\end{result}

The flip negates the z-score before briefing generation, producing a near-symmetric reversal ($+0.74 \to -0.69$). This makes it unlikely that the baseline correlation reflects structural features of the prompt or model-specific tendencies.

\begin{figure*}[htbp]
  \centering
  \includegraphics[width=\textwidth]{figures/fig03_falsification.pdf}
  \caption{Falsification triptych. \textit{Left:} Pure global game (mean $r = +0.74$). \textit{Center:} Cross-period scramble breaks the $\theta$-to-briefing mapping (mean within-country $r = +0.07$). \textit{Right:} Signal flip inverts the mapping (mean $r = -0.69$). Each panel pools data from models with full falsification suites.}
  \label{fig:falsification}
\end{figure*}

The pure $\to$ scramble $\to$ flip pattern replicates across all seven models with full falsification suites (Table~\ref{tab:main_results}). Every model shows strong positive correlation under pure, collapse under scramble (within-country $r$), and sign reversal under flip.

The briefing generator maps z-scores monotonically to text---could a model that simply reads briefing sentiment, without any strategic reasoning, produce the observed sigmoid? To test this, I construct the simplest possible text-only predictor.

The generator assigns each briefing an internal \textit{direction} score $d \in [0,1]$, where $d = 1$ indicates regime-favorable language. A naive baseline predicts $\hat{p}_{\text{join}} = 1 - d$: join whenever the text sounds bad for the regime. This is the prediction a pure sentiment reader would make.

The correlation between this baseline and actual LLM decisions is $r = 0.80$---confirming that the text carries signal (as designed, since briefings are constructed to convey z-score content). However, the LLM's empirical join curve is substantially steeper than the text baseline (Figure~\ref{fig:text_baseline}). The fitted logistic has slope 1.78, producing a sharp transition around $z = 0$, while the text baseline drifts gradually from $\approx 0.93$ to $\approx 0.10$ across the full z-score range. The encoder is essentially monotone ($r(z, d) = 0.995$).

The gap between the text baseline and the empirical sigmoid indicates that the LLM sharpens the signal beyond surface sentiment, producing threshold-like behavior rather than linearly tracking the briefing's tone. This is consistent with---though does not prove---strategic information processing.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\columnwidth]{figures/fig15_text_baseline.pdf}
  \caption{Text baseline identification test. Blue: empirical LLM join rate across z-scores. Orange: naive text-only predictor ($1 - \text{direction}$, $r = 0.80$). Red: fitted logistic (slope = 1.78). The LLM produces a steeper transition than the text baseline, indicating processing beyond sentiment reading. Mistral Small Creative, 210 observations.}
  \label{fig:text_baseline}
\end{figure}

A stronger test asks whether agents form beliefs about others' behavior consistent with the equilibrium prediction. After each decision, I elicit stated beliefs by asking agents: ``On a scale from 0 to 100, how likely do you think the uprising will succeed?'' I run this elicitation under three treatments---pure, communication, and surveillance---each with 200 country--periods (${\approx}\,5{,}000$ agent-level observations per treatment). In the pure treatment, stated beliefs correlate strongly with the Bayesian posterior $P(\text{success} \mid x_i) = \Phi[(\theta^* - x_i)/\sigma]$ ($r = +0.79$, $p < 0.001$; Figure~\ref{fig:beliefs}a). Beliefs track the posterior with systematic underconfidence (slope $< 1$), but the direction and rank ordering are preserved. The pattern holds across treatments: $r = +0.79$ under communication and $r = +0.78$ under surveillance.

Actions are strongly monotone in stated beliefs ($r = +0.84$ in pure, $+0.83$ in communication, $+0.73$ in surveillance). The join rate as a function of belief is steep in the pure treatment: agents with beliefs below 40\% rarely join, while those above 80\% almost always join. The notably lower belief--action correlation under surveillance ($r = +0.73$ vs.\ $+0.84$ under pure) is itself evidence of preference falsification: surveillance disrupts the link between private beliefs and public actions. Communication leaves mean beliefs unchanged relative to pure ($44.4\%$ vs.\ $44.4\%$, $\Delta = 0.0$~pp) and has a negligible effect on join rates in this sample ($-0.6$~pp). The eight-model pooled effect on join rates is small and not statistically significant (Section~\ref{sec:communication}); the sign varies across models, consistent with the communication channel introducing strategic uncertainty rather than uniformly promoting coordination. Crucially, beliefs predict decisions beyond what the signal alone predicts: the belief--action correlation ($r = +0.84$) substantially exceeds what surface sentiment alone would produce (the text baseline achieves $r = 0.80$). This pattern is consistent with strategic reasoning about others' likely actions.\footnote{The belief elicitation data is from a single model (Mistral Small Creative). However, the behavioral patterns that belief data explains---the surveillance chilling effect and the communication--action gap---replicate across three architectures (Mistral, Llama, Qwen3), suggesting the underlying mechanism generalizes beyond the model for which beliefs were directly measured.}

\begin{figure*}[htbp]
  \centering
  \includegraphics[width=\textwidth]{figures/fig16_beliefs.pdf}
  \caption{Belief elicitation results (Mistral Small Creative, 200 country--periods per treatment, ${\approx}\,5{,}000$ agent observations each). \textit{Left:} Stated beliefs track the Bayesian posterior $P(\text{success} \mid x_i)$ with $r = +0.79$ and systematic underconfidence (slope $= 0.57$). Dashed line: perfect calibration. \textit{Right:} Join rate by stated belief bin under four treatments. Agents with 60--80\% beliefs join at 86\% in the pure treatment but only 58\% under surveillance. Propaganda preserves the belief--posterior correlation while suppressing actions---consistent with a mechanical rather than belief-based channel.}
  \label{fig:beliefs}
\end{figure*}

Second-order beliefs---agents' predictions about \textit{others'} join rates---provide a sharper test of strategic reasoning. I elicit these by asking each agent: ``Out of 100 citizens in a similar situation, how many do you think would choose to JOIN?'' Across 200 country--periods per treatment (${\approx}\,5{,}000$ agent observations each), second-order beliefs track the private signal ($r = -0.73$, $p < 0.001$) and vary monotonically with regime strength, consistent with agents reasoning about others' likely responses to correlated signals (Figure~\ref{fig:second_order_beliefs}). Crucially, surveillance does \textit{not} shift second-order beliefs (mean $31.2\% \to 30.9\%$, $\Delta = -0.3$~pp, $p = 0.59$) but \textit{does} shift behavior ($-13.4$~pp). The result is a belief--behavior gap that \textit{reverses direction} across treatments: in the pure treatment, agents predict $31\%$ will join but $42\%$ actually do (underprediction); under surveillance, agents still predict $31\%$ but only $28.5\%$ actually do (slight overprediction). The shift in behavior ($-13.4$~pp) dwarfs the shift in beliefs ($-0.3$~pp), precisely the signature of preference falsification in the sense of \citet{kuran1991}---surveillance changes what agents \textit{do} without changing what they \textit{believe} others would do, because the chilling effect operates through self-censorship rather than through belief updating.

\begin{figure*}[htbp]
  \centering
  \includegraphics[width=\textwidth]{figures/fig17_second_order_beliefs.pdf}
  \caption{Second-order beliefs (Mistral Small Creative). \textit{Left:} Mean second-order belief---agents' predicted join rate---decreases with regime strength $\theta$ across all treatments, confirming that beliefs track the private signal. Surveillance (purple) overlaps almost exactly with pure (gray), while communication (blue) slightly compresses the range. \textit{Right:} Second-order belief vs.\ actual period-level join rate. Agents are approximately calibrated: the regression lines track the 45-degree perfect-calibration reference (dashed).}
  \label{fig:second_order_beliefs}
\end{figure*}

%% ============================================================
%% 7. COMMUNICATION
%% ============================================================
\section{Communication} \label{sec:communication}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\columnwidth]{figures/fig05_communication.pdf}
  \caption{Communication effect by regime strength, pooled across eight models. Communication increases join rates for weak regimes ($\theta < \theta^*$) but has no effect or slightly reduces join rates for strong regimes ($\theta > \theta^*$).}
  \label{fig:communication}
\end{figure}

\begin{result}[Communication has a small, heterogeneous effect]
Pre-play communication raises the mean join rate by \CommDeltaPPModelAvg~pp, from \CommPureMeanModelAvg to \CommCommMeanModelAvg, averaged across eight models. In the pooled sample, the unpaired difference is \CommDeltaPPPooled~pp ($p = \CommPValueUnpaired$); effects vary in sign across models and are concentrated in weak-regime environments.\footnote{I report the unpaired (between-period) test as the primary specification because pure and communication treatments use independent $\theta$ draws, so country--periods are not naturally matched. A paired test that matches periods within each model by $\theta$-rank yields a significant positive effect ($+5.5$~pp, $p < 0.001$, $n = 680$ pairs), reflecting within-$\theta$ variation that the unpaired test averages over. The qualitative conclusion---that the effect is small relative to baseline variation and heterogeneous across models---is robust to both approaches.}
\end{result}

Agents send a message to their network neighbors and observe received messages before deciding. The effect is heterogeneous across models: five of eight show positive effects ($+0.1$ to $+3.5$~pp), while three show negative effects ($-2.4$ to $-4.6$~pp). The communication premium is not structurally robust: the pooled average is near zero, and its sign depends on model-specific features of information processing. Communication leaves equilibrium-alignment correlations essentially unchanged (mean across models: $r = +0.73$ under comm vs.\ $+0.74$ under pure), preserving the signal structure while introducing strategic uncertainty about others' actions. The asymmetry across $\theta$ is consistent with passive Bayesian updating: agents update toward joining when neighbors' correlated signals reveal regime weakness, with a floor effect preventing further declines under strong regimes where join rates are already near zero.

The belief elicitation data (Section~\ref{sec:falsification}) confirms that communication introduces strategic uncertainty without systematically shifting beliefs. Mean stated beliefs are identical under communication and pure (44.4\%), yet the communication channel opens a vector for authoritarian exploitation. The remaining sections show that this vulnerability is precisely what information control exploits.

The communication effect is also sensitive to what agents know about the coordination environment. In a robustness check (Appendix~\ref{sec:robustness}), agents are told ``you are one of 25 citizens''---providing a basis for threshold reasoning absent in the main experiment. With group-size knowledge, the communication premium reverses: communication \textit{lowers} join rates by 3.4~pp rather than raising them. When agents can reason about critical mass, messages revealing others' reluctance become more informative about the probability of reaching the coordination threshold, amplifying the deterrent effect of cautious peers. This reinforces the interpretation that communication's net effect on coordination is theoretically ambiguous: the same channel that transmits information about regime weakness also transmits evidence of others' caution.


%% ============================================================
%% 8. INFORMATION DESIGN
%% ============================================================
\section{Information Design} \label{sec:infodesign}

As noted at the end of Section~\ref{sec:results}, from this section onward I report $r(J, \theta)$ directly on a fixed $\theta$-grid, which is \textit{negative} under equilibrium alignment.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\columnwidth]{figures/fig07_all_designs.pdf}
  \caption{Join fraction as a function of $\theta$ under six information designs. Baseline, stability, and censorship designs have $N = 270$; instability and public signal have $N = 540$. Upper censorship pools weak-regime states; lower censorship pools strong-regime states and produces a dramatic reversal above $\theta^*$. Mistral Small Creative model.}
  \label{fig:all_designs}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\columnwidth]{figures/fig08_treatment_effect.pdf}
  \caption{Treatment effect $\Delta(\theta) = \text{design join} - \text{baseline join}$ as a function of $\theta$. Negative values indicate the design suppresses coordination.}
  \label{fig:treatment_effect}
\end{figure}

Table~\ref{tab:infodesign_summary} summarizes the main results. The baseline condition produces a mean join rate of \InfodesignBaselineMeanPct with a strong negative correlation between $\theta$ and join fraction ($r = \InfodesignBaselineRTheta$, $p < 0.001$).

\begin{result}[Information Design Shifts Coordination]
All three information designs produce measurable shifts in coordination relative to baseline.
\end{result}

The stability design suppresses coordination on average: mean join falls from \InfodesignBaselineMeanPct to \InfodesignStabilityMeanPct (\InfodesignStabilityDeltaPP~pp relative to baseline), and the $\theta$--join relationship flattens ($r = \InfodesignStabilityRTheta$ vs.\ \InfodesignBaselineRTheta). The suppression is present at every $\theta$ grid point. This pattern is consistent with the design injecting ambiguity and mixed evidence near $\theta^*$: weak-regime briefings retain stabilizing cues that deter participation even when fundamentals favor an uprising.

The instability design reduces the mean join rate to \InfodesignInstabilityMeanPct (\InfodesignInstabilityDeltaPP~pp relative to baseline). Sharper signals allow agents to more confidently distinguish strong from weak regimes, reducing participation across the grid.

The public signal produces the largest reduction in coordination: mean join rate falls to \InfodesignPublicSignalMeanPct (\InfodesignPublicSignalDeltaPP~pp relative to baseline). The shared bulletin is common knowledge and tends to dominate private briefings, sharply attenuating private-signaldriven participation. The correlation between $\theta$ and join fraction drops to $r = \InfodesignPublicSignalRTheta$, consistent with heavy weight on the public channel.

\input{tables/tab_infodesign_summary.tex}

\citet{kolotilin2022} proved that when a sender's marginal utility is quasi-concave, the optimal information structure is upper censorship---one-sided pooling that conceals unfavorable states. In the language of Bayes-correlated equilibria, the regime designer chooses a signal structure that maximizes its objective subject to receivers' obedience constraints. Upper censorship implements this by pooling weak-regime states ($\theta \le \theta^*$) into a neutral signal, so that agents who would otherwise observe evidence of regime vulnerability instead receive an uninformative briefing. Lower censorship applies the mirror image: strong-regime states are pooled. I implement both designs.

\begin{figure*}[htbp]
  \centering
  \includegraphics[width=\textwidth]{figures/fig09_censorship.pdf}
  \caption{Censorship effects. \textit{Left:} Join fraction under upper and lower censorship vs.\ baseline. Upper censorship pools weak-regime states ($\theta \le \theta^*$), creating a flat plateau. Lower censorship pools strong-regime states ($\theta \ge \theta^*$) and produces a sharp reversal: join rates jump at $\theta^*$ and remain elevated. \textit{Right:} OLS slope decomposition across all designs.}
  \label{fig:censorship}
\end{figure*}

\begin{result}[Upper Censorship Suppresses Joining in Weak States]
Upper censorship lowers the mean join rate to \InfodesignCensorUpperMeanPct (\InfodesignCensorUpperDeltaPP~pp vs.\ baseline) and attenuates the slope of the $\theta$--join relationship ($r = \InfodesignCensorUpperRTheta$). The effect is concentrated in the censored region ($\theta \le \theta^*$), where weak-regime states are pooled to a neutral briefing and join rates flatten.
\end{result}

Pooling generates a flat join-rate ``plateau'' in the censored region: when agents cannot distinguish $\theta = 0.20$ from $\theta = 0.50$, they behave as if the regime is borderline rather than clearly weak.\footnote{The pooling effect requires agents to be na\"ive about censorship. When agents are told that ``regime censors are suppressing unfavorable intelligence above a certain severity threshold,'' the mean join rate returns to the uncensored baseline ($43.2\%$ vs.\ $43.7\%$; Appendix~\ref{sec:censor_ck}). Common knowledge of the censorship rule largely neutralizes the pooling distortion.}

\begin{result}[Lower Censorship Reverses Comparative Statics]
Lower censorship produces a mean join rate of \InfodesignCensorLowerMeanPct (\InfodesignCensorLowerDeltaPP~pp vs.\ baseline) and flips the comparative statics: the $\theta$--join correlation becomes positive ($r = \InfodesignCensorLowerRTheta$). Below $\theta^*$, censoring favorable signals suppresses joining (agents see only weak-regime cues); above $\theta^*$, pooling strong-regime states to a neutral briefing \textit{raises} join rates sharply---agents who would otherwise see discouraging intelligence now receive uninformative briefings and default toward joining. The discontinuity at $\theta^*$ is consistent across repetitions (within-cell $\sigma < 0.04$) and replicates across models, though the direction of the reversal is model-dependent (Appendix~\ref{sec:robustness}).
\end{result}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\columnwidth]{figures/fig10_infodesign_falsification.pdf}
  \caption{Falsification within information design. Scrambling collapses the $\theta$-join correlation to $r = +0.037$; flipping inverts it to $r = +0.823$.}
  \label{fig:infodesign_falsification}
\end{figure}

Under the scramble condition, the correlation between $\theta$ and join fraction collapses to $r = +0.037$ ($p = 0.55$). Under the flip condition, the correlation inverts to $r = +0.823$ ($p < 0.001$) with mean join rate soaring to 66.3\%. These results confirm that the information design effects operate through the intended signal channel.


%% ============================================================
%% 9. SURVEILLANCE
%% ============================================================
\section{Surveillance and the Strategic Update Gap} \label{sec:surveillance}

\citet{kuran1991} argued that authoritarian regimes sustain themselves partly through preference falsification. I test this by introducing a surveillance treatment in the communication game.

In the surveillance treatment, the communication prompt is augmented with a warning that communications are being monitored by regime security services. The surveillance manipulation affects only the communication phase; the decision prompt is unchanged. The isolation is architectural: each LLM call is stateless, consisting of a fresh system prompt and user prompt with no conversation history. The decision-stage system prompt contains no reference to surveillance---it is identical to the standard communication decision prompt. The decision-stage user prompt contains only the private briefing and received messages. The agent's decision call has no knowledge that surveillance was active during the communication phase; it observes only the (self-censored) messages that resulted from it. Any difference in join rates must therefore arise from agents self-censoring their communications, not from a direct change in the perceived cost of joining. Two additional variants confirm this: a placebo (``monitored for research, no consequences'') and an anonymous variant (``aggregated anonymously'') produce no significant deviation from the communication baseline ($+2.6$~pp and $+4.1$~pp respectively, both $p > 0.2$; Appendix~\ref{sec:surv_isolation}), establishing that the chilling effect is specific to the surveillance warning's strategic content.

\begin{figure*}[htbp]
  \centering
  \includegraphics[width=\textwidth]{figures/fig12_surveillance.pdf}
  \caption{Join rates under regular communication vs.\ surveillance communication. Surveillance reduces join rates by 11.1 percentage points on average ($p < 0.001$). Results shown for three models: Mistral ($-13.4$~pp), Llama ($-8.9$~pp), and Qwen3 ($-10.9$~pp).}
  \label{fig:surveillance}
\end{figure*}

\begin{result}[Surveillance Produces a Large Chilling Effect]
In the primary model (Mistral Small Creative), surveillance reduces mean join rates from 41.1\% to 27.8\%, a difference of 13.4 percentage points ($p < 0.001$). The correlation between $\theta$ and join fraction is preserved under surveillance ($r = -0.809$ vs.\ $-0.802$), indicating that surveillance operates as a level shift rather than disrupting signal processing.
\end{result}

Surveillance contaminates the information environment with self-censored messages, pushing join rates well below the communication baseline. The effect replicates across three architectures: Mistral ($-13.4$~pp), Llama ($-8.9$~pp), and Qwen3 ($-10.9$~pp), averaging $-11.1$~pp.

The belief elicitation data confirms that this is preference falsification in the sense of \citet{kuran1991}, not belief updating. Surveillance shifts stated beliefs by only 0.7~pp relative to pure ($p = 0.25$, not significant) while shifting join rates by 13.4~pp ($p < 0.001$)---a ratio of nearly 20:1. The belief--action correlation drops sharply under surveillance ($r = +0.73$ vs.\ $+0.84$ under pure), directly measuring the wedge that preference falsification drives between private beliefs and public actions.

The most striking finding concerns second-order beliefs. Agents' predictions about \textit{others'} join rates are essentially unchanged by surveillance ($31.2\% \to 30.9\%$, $p = 0.59$; Section~\ref{sec:falsification}). This reveals a \textit{strategic update gap}: surveillance alters each agent's individual threshold for expressing dissent without updating their model of the population threshold. Agents self-censor because they fear personal consequences, but they do not realize that everyone else is also self-censoring. They interpret others' silence as genuine regime support rather than as the product of the same fear they themselves experience. This failure to reach common knowledge of the chilling effect is what makes preference falsification so durable---each agent believes they are \textit{uniquely} cautious, sustaining the equilibrium even though the underlying beliefs that would support coordination remain intact. Once agents expect others to self-censor, even authentic messages become uninformative, and the entire communication channel is poisoned.

The information leakage confirms this quantitatively. Regressing the true state $\theta$ on observable linguistic features of the messages, the $R^2$ drops from 0.12 under regular communication to 0.02 under surveillance---an 80\% reduction in the informational content transmitted through the network. Surveillance does not merely mute the channel; it structurally degrades it, replacing informative signals with self-censored noise that is uninformative about the true state.

The strategic update gap has a direct parallel in AI alignment. Preference falsification under observation---altering expressed behavior while maintaining internal states---is structurally identical to the deceptive alignment concern: a model that produces aligned outputs during evaluation while its internal representations remain unchanged \citep{hubinger2019}. The surveillance result shows this behavior emerges from pretraining on human text about strategic interaction, without any explicit optimization for deception. Moreover, the gap replicates across three architecturally distinct models (Mistral, Llama, Qwen3), suggesting it is a convergent property of language models trained on sufficient strategic reasoning data rather than an artifact of any particular architecture or training procedure.

Message content confirms the self-censorship directly. Across 15,000 communication messages and 25,000 surveillance messages, surveillance agents write shorter messages (253 vs.\ 342 characters) and systematically avoid action language: ``act'' appears in 19.0\% of communication messages but only 3.8\% under surveillance; ``collapse'' drops from 11.6\% to 0.6\%; ``together'' from 7.2\% to 0.7\%. In its place, hedged and cautious language rises: ``careful'' (1.5\% $\to$ 4.8\%), ``stable'' (1.7\% $\to$ 4.2\%), ``patience'' (0.3\% $\to$ 2.4\%). Among agents who privately decide to JOIN, only 19.0\% send action-signaling messages under surveillance, compared to 46.1\% under regular communication. Surveillance agents who intend to join write messages like \textit{``the air feels lighter\ldots keep your eyes open, but step carefully''} rather than \textit{``the walls are cracking---the machine is grinding to a halt.''} The decision is the same; the expressed sentiment is not.


%% ============================================================
%% 10. PROPAGANDA
%% ============================================================
\section{Propaganda: Information Contamination} \label{sec:propaganda}

\citet{edmond2013} modeled propaganda as the regime shifting citizens' signal distributions. I implement this by introducing propaganda agents---regime plants who transmit fixed pro-regime messages and always STAY.

\begin{figure*}[htbp]
  \centering
  \includegraphics[width=\textwidth]{figures/fig13_propaganda.pdf}
  \caption{Dose-response relationship between number of propaganda agents and mean join rate. Results shown for Mistral (primary) and Llama (replication). Regular communication ($k = 0$) serves as baseline.}
  \label{fig:propaganda}
\end{figure*}

\begin{result}[Propaganda Suppresses Coordination Primarily Through Mechanical Dilution]
Mean join fraction (including plants) falls from 41.1\% ($k = 0$) to 37.5\% ($k = 2$), 31.3\% ($k = 5$), and 23.3\% ($k = 10$). However, the behavioral effect on real citizens is much smaller and saturates: 41.1\% ($k = 0$), 40.7\% ($k = 2$, $-0.4$~pp), 39.1\% ($k = 5$, $-2.0$~pp), 38.8\% ($k = 10$, $-2.3$~pp).
\end{result}

Propaganda works through two channels: a \textit{mechanical} channel (plants always STAY, directly reducing attack mass) and a \textit{behavioral} channel (pro-regime messages reduce real citizens' willingness to join). The mechanical channel is approximately linear in $k$; the behavioral channel is small and saturates quickly---doubling plants from 5 to 10 produces essentially no additional behavioral effect ($-0.3$~pp, $p = 0.67$). This decomposition implies sharply diminishing returns to propaganda investment: the regime's first few plants yield both mechanical and behavioral suppression, but additional plants contribute only mechanical dilution. In \citet{edmond2013}'s framework, this corresponds to a concave regime payoff in propaganda intensity---the marginal value of an additional plant falls rapidly once the behavioral channel is exhausted. At $k = 10$ (40\% of the network), real citizens' join rate has barely moved from $k = 5$ (39.1\% vs.\ 38.8\%), suggesting that citizens learn to discount pro-regime messaging after sufficient exposure.

The propaganda effect replicates with Llama 3.3 70B, which shows a behavioral effect of $-2.7$~pp at $k = 5$, confirming the qualitative pattern and the saturation across architectures.

Message content reveals the mechanism. Propaganda agents inject regime-loyal vocabulary into the communication network, and this language propagates to real agents. The fraction of messages containing ``loyal'' rises from 1.5\% at baseline to 3.5\% ($k = 2$), 6.1\% ($k = 5$), and 11.4\% ($k = 10$); ``patience'' rises from 0.3\% to 5.1\%. Meanwhile, coordination language declines: ``ready'' falls from 30.5\% to 18.5\%, ``together'' from 7.2\% to 4.2\%. Message length also shrinks (342 $\to$ 285 characters), consistent with the shorter, punchier pro-regime messages diluting the discourse. Among real agents who STAY, the fraction sending caution-coded messages rises from 24.2\% (baseline) to 38.2\% ($k = 10$)---agents are not merely responding to propaganda but \textit{echoing} it. Among those who JOIN, however, action signaling remains stable at ${\approx}\,86\%$ across all conditions. The behavioral saturation documented above thus has a linguistic correlate: propaganda shifts the discourse for agents on the margin, but agents with strong anti-regime signals continue to express and act on their beliefs regardless of the propaganda dose.

\input{tables/tab_surveillance_propaganda.tex}


%% ============================================================
%% 12. INSTRUMENT INTERACTIONS
%% ============================================================
\section{Instrument Interactions} \label{sec:interactions}

The preceding sections analyzed surveillance, censorship, and propaganda in isolation. A regime, however, deploys these instruments jointly. This section tests whether the instruments interact as substitutes (diminishing returns) or complements (super-additive suppression).

\begin{result}[Propaganda $+$ Surveillance: Approximately Additive]
When propaganda ($k = 5$) and surveillance are combined, the mean join rate among real citizens falls to 24.3\%, a reduction of 16.8~pp from the communication baseline (41.1\%). The sum of individual effects is 15.4~pp (surveillance $-13.4$~pp $+$ propaganda $-2.0$~pp), so the combined effect (16.8~pp) is approximately additive. Once surveillance has suppressed expressed dissent, propaganda adds only modest additional deterrence.
\end{result}

\begin{result}[Surveillance $\times$ Censorship: Super-Additive]
Table~\ref{tab:surv_censor} shows that surveillance and censorship interact strongly: surveillance sharply suppresses coordination, and its marginal effect is substantially larger under censorship than at baseline. In this sense the interaction is super-additive---censorship increases reliance on the communication channel, and surveillance poisons that channel.
\end{result}

Surveillance and censorship are complements that attack different links in the coordination chain. Censorship removes the private information channel, forcing agents to rely on communication for their signals about regime strength. Surveillance then poisons that communication channel through preference falsification. With both instruments active, agents have neither private signals to trust nor authentic messages to learn from---the informational foundations of coordination are eliminated from both directions.

This complementarity is the mechanism behind the paper's headline result: pooling interventions can shift coordination by distorting private information, but once surveillance contaminates the messaging stage, the same communication channel becomes a lever for suppressing coordination. The regime does not need each instrument to be independently decisive; it needs the combination to close every informational pathway through which coordination might flow.

\input{tables/tab_surv_censor.tex}

The interaction between surveillance and censorship is heterogeneous across architectures (Table~\ref{tab:surv_censor_crossmodel}). Under communication with surveillance, baseline join rates range from near zero (Mistral, 0.9\%) to roughly one-third (GPT-OSS~120B, 31.6\%; Qwen3~235B, 33.6\%). Under surveillance, upper censorship further suppresses coordination for Llama~70B and GPT-OSS~120B, but has little effect for Qwen3~235B and \textit{raises} joining modestly for Mistral. Lower censorship is similarly mixed: it has essentially no effect for Llama and GPT-OSS, but increases join rates for Mistral and Qwen3~235B. The regime-control instruments therefore do not combine mechanically; the joint effect depends on model-specific resolution of pooled private signals and self-censored messages.

\input{tables/tab_surv_censor_crossmodel.tex}

\begin{figure*}[htbp]
  \centering
  \includegraphics[width=\textwidth]{figures/diagram_authoritarian_control.pdf}
  \caption{How authoritarian instruments attack the coordination chain. Surveillance poisons the communication channel through preference falsification; censorship degrades the private signal channel by pooling states; propaganda contaminates the communication channel mechanically. Surveillance and censorship are complements (super-additive), while propaganda's behavioral effect saturates quickly.}
  \label{fig:authoritarian_control}
\end{figure*}


%% ============================================================
%% 14. CONCLUSION
%% ============================================================
\section{Conclusion} \label{sec:conclusion}

The central finding of this paper is that the information channel is a trap. Modern authoritarianism relies less on terror and more on information manipulation \citep{guriev2019}. The global games framework clarifies why this is effective: coordination requires overcoming strategic uncertainty, which necessitates communication. But the very act of opening a communication channel provides the regime with the surface area required to deploy surveillance and censorship. Any channel that transmits information about others' willingness to act also transmits \textit{uncertainty} about others' willingness to act, and that uncertainty is exploitable.

The experimental results demonstrate that the regime does not need to change what citizens privately believe. It needs only to fracture the common knowledge of those beliefs. Communication does not shift agents' beliefs about success ($44.4\%$ under both pure and communication), yet the channel it opens is vulnerable. Surveillance compounds this ($-13.4$~pp for Mistral, $-11.1$~pp on average) through preference falsification in the sense of \citet{kuran1991}: agents maintain their private beliefs but self-censor, generating a cascade of uninformative messages that poisons the channel for everyone. The strategic update gap documented in Section~\ref{sec:surveillance}---second-order beliefs unchanged ($31.2\% \to 30.9\%$) while actual join rates fall by 13.4~pp---shows that surveillance operates asymmetrically on beliefs, altering individual thresholds without updating agents' models of the population threshold. This is what makes preference falsification durable: each agent suppresses dissent while interpreting others' silence as genuine.

Censorship and surveillance are complements that attack different links in the coordination chain. Censorship pools private signals, forcing agents to rely on communication; surveillance then poisons that communication channel. With both instruments active, agents have neither private signals to trust nor authentic messages to learn from. Propaganda's behavioral channel, by contrast, is small and saturates quickly (the effect is largely exhausted by $k = 5$ plants), implying diminishing returns; the marginal authoritarian dollar is better spent on surveillance than on additional propaganda.

The findings also speak to AI alignment. Three results are relevant. First, preference falsification under surveillance---strategically misrepresenting expressed preferences while maintaining private beliefs---emerges without any training signal for deceptive behavior. The models have internalized the pattern of strategic self-censorship from pretraining on human text, and this pattern is robust across architectures spanning 3B to 235B parameters. For alignment, this suggests that deception-adjacent capabilities need not be explicitly optimized; they can emerge as a byproduct of learning to model human strategic reasoning. Second, the belief-mediation result (Pseudo $R^2 = 0.975$) shows that LLMs form opaque internal states that fully determine behavior---the raw signal adds nothing once beliefs are controlled for. Alignment techniques that monitor inputs and outputs without access to these intermediate representations may miss the locus of decision-relevant computation. Third, the information design results demonstrate that LLMs are systematically manipulable through the \textit{structure} of information, not just its content: censorship, ambiguity injection, and public signals shift behavior by up to 40 percentage points without the model detecting the manipulation. This cuts both ways---alignment interventions operating through information structure (system prompts, constitutional AI) can be effective, but adversarial prompt design can systematically shift model behavior in ways the model itself cannot distinguish from authentic information.

I do not claim that LLMs are Bayesian agents---the mechanism by which they process narrative text likely differs fundamentally from Bayesian updating. But across eight architecturally distinct models (mean $r = +0.74$, $p < 0.001$), the behavioral regularities are precisely what the global games framework predicts: monotone response to signal content, threshold-like decisions, sensitivity to information design, and preference falsification under surveillance. The consistency across architectures spanning 3B to 235B parameters suggests these regularities are not artifacts of any particular training procedure. LLMs are trained on the same informational diet---political analysis, news reporting, strategic reasoning---that shapes how citizens form beliefs about regime stability. The question is not whether they reason identically to humans, but whether the regularities are robust enough to serve as a computational laboratory for predictions that are difficult to test otherwise. The full regime change game has resisted laboratory implementation because it requires rich private signals, genuine strategic uncertainty, and large groups. LLM agents sidestep these constraints, and the same platform extends naturally to currency crises, bank runs, and other coordination games where information processing is central to behavior.


%% ============================================================
%% REFERENCES
%% ============================================================
\FloatBarrier
\begingroup
\setlength{\bibsep}{0pt}
\setlength{\itemsep}{0pt}
\scriptsize
\renewcommand{\baselinestretch}{0.93}\selectfont
\bibliographystyle{plainnat}
\bibliography{references}
\endgroup

\clearpage
\appendix
\renewcommand{\thefigure}{A\arabic{figure}}
\setcounter{figure}{0}
\renewcommand{\thetable}{A\arabic{table}}
\setcounter{table}{0}


%% ============================================================
%% APPENDIX A: DECOMPOSITION
%% ============================================================
\section{Decomposition: Which Channel Drives the Stability Effect?} \label{sec:decomposition}

The stability design manipulates three channels simultaneously (direction, clarity, dissent). To determine which drives the effect, I run three single-channel treatments, each activating only one manipulation while holding the other two at baseline.

\begin{figure*}[htbp]
  \centering
  \includegraphics[width=0.85\textwidth]{figures/fig11_decomposition.pdf}
  \caption{Single-channel decomposition of the stability design. Each curve shows join fraction vs.\ $\theta$ when only one channel (clarity, direction, or dissent) is manipulated, with the other two held at baseline. All three single-channel effects are large and similar in magnitude.}
  \label{fig:decomposition}
\end{figure*}

Each channel alone produces a large suppression of joining relative to baseline: clarity only (\DecompClarityOnlyDeltaPP~pp), direction only (\DecompDirectionOnlyDeltaPP~pp), and dissent only (\DecompDissentOnlyDeltaPP~pp).

\input{tables/tab_decomposition.tex}

Summing the single-channel effects yields \DecompSumChannelsDeltaPP~pp, far larger in magnitude than the bundled stability design effect (\DecompFullDeltaPP~pp). This implies strong non-additivity: the channels do not add linearly and largely offset when combined.


%% ============================================================
%% APPENDIX B: ROBUSTNESS
%% ============================================================
\section{Robustness} \label{sec:robustness}

\begin{figure}[htbp]
  \centering
  \begin{subfigure}{0.49\columnwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/figA1_agent_count.pdf}
    \caption{Agent count variation ($n \in \{5, 10, 25, 50, 100\}$).}
  \end{subfigure}\hfill
  \begin{subfigure}{0.49\columnwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/figA2_network.pdf}
    \caption{Network density ($k = 4$ vs.\ $k = 8$).}
  \end{subfigure}

  \begin{subfigure}{0.98\columnwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/figA3_bandwidth.pdf}
    \caption{Bandwidth sensitivity (0.05, 0.15, 0.30).}
  \end{subfigure}
  \caption{Robustness checks for equilibrium alignment and treatment effects.}
  \label{fig:robustness}
\end{figure}

These checks show that equilibrium alignment and the qualitative information design effects are stable to agent count, network density, and the proximity bandwidth.

\subsection{Agent Count Variation}

I vary the number of agents per period ($n \in \{5, 10, 25, 50, 100\}$) using Mistral Small Creative. The correlation is stable: $r = +0.60$ ($n = 5$), $r = +0.63$ ($n = 10$), $r = +0.68$ ($n = 25$), $r = +0.65$ ($n = 50$), $r = +0.65$ ($n = 100$). The slight increase from $n = 5$ to $n = 25$ likely reflects reduced discretization noise.

\subsection{Network Topology}

I compare the baseline communication network ($k = 4$) with a denser network ($k = 8$). The denser network produces $r = +0.66$ (vs.\ $+0.65$ for $k = 4$), with a similar mean join rate of 0.41 in both conditions. Additional contacts do not substantially amplify coordination.

\subsection{Mixed-Model Games}

A five-model mixed-population game produces $r = +0.77$ (pure) and $r = +0.75$ (communication)---if anything, higher than single-model correlations. Equilibrium alignment is not an artifact of model homogeneity.

\subsection{Calibration Robustness Across Models}

The main experiments calibrate a single parameter (cutoff center) per model to center the sigmoid at $z = 0$. A natural concern is whether the monotone threshold pattern is an artifact of this calibration step. To test this, I run the pure global game with default parameters (cutoff center $= 0$, no calibration) for three architecturally distinct models. The correlation between regime strength $\theta$ and join fraction remains strongly negative for all three: Mistral Small Creative ($r = -0.865$, $p < 10^{-30}$), Llama~3.3~70B ($r = -0.875$, $p < 10^{-32}$), and Qwen3~235B ($r = -0.857$, $p < 10^{-29}$). All three exceed $|r| > 0.85$ with default parameters, confirming that the sigmoid relationship is an emergent property of how these models process narrative signals rather than an artifact of the calibration procedure. Calibration shifts the center of the response function but does not create the monotone structure (Table~\ref{tab:uncalibrated}).

\input{tables/tab_uncalibrated.tex}

Table~\ref{tab:calibration_robustness} reports calibration quality metrics across all eight models. The raw correlation $r_\theta$ between regime strength and join fraction ranges from $-0.79$ to $-0.87$, confirming stable monotone response across architectures.

\input{tables/tab_calibration_robustness.tex}

\begin{figure*}[htbp]
  \centering
  \includegraphics[width=0.85\textwidth]{figures/figA4_calibration.pdf}
  \caption{Calibration convergence. \textit{Left:} Trajectory of the fitted logistic center $c$ across autocalibration rounds for each model. The green band marks the convergence criterion ($|c| < 0.15$). All models converge within 2--3 rounds. \textit{Right:} Final calibrated cutoff center per model. Most models require only modest shifts ($|c| < 0.3$).}
  \label{fig:calibration_convergence}
\end{figure*}

\subsection{Bandwidth Sensitivity}

\input{tables/tab_bandwidth.tex}

Qualitative treatment effects are robust across bandwidths, though magnitudes vary---especially for the stability design, whose effect peaks at the baseline bandwidth. The baseline bandwidth of 0.15 is approximately optimal for detecting treatment effects on the experimental grid.

\subsection{Cross-Model Replication of Information Design}

\begin{figure*}[htbp]
  \centering
  \includegraphics[width=0.85\textwidth]{figures/fig14_cross_model_infodesign.pdf}
  \caption{Cross-model replication of information design treatments. Each panel shows join fraction vs.\ $\theta$ for one model under baseline, stability, scramble, and flip conditions.}
  \label{fig:oa_crossmodel_infodesign}
\end{figure*}

Table~\ref{tab:crossmodel} reports cross-model replication of information design treatments. The flip inversion replicates across all models tested ($r > +0.43$ for all five). The scramble test shows more heterogeneity: Mistral, GPT-OSS, and Qwen3 235B show clean collapse ($r \approx 0$), but Llama 3.3 70B and Ministral 3B retain baseline-level correlations under scramble ($r = -0.81$ and $r = -0.66$), suggesting these models extract signal from features the scramble does not disrupt (e.g., within-country narrative coherence). Qwen3 30B shows a large reduction in correlation under scramble and a clear flip effect.

\input{tables/tab_crossmodel.tex}

\subsection{Information Design with Communication}

In a communication version of the information-design grid (same 9-point $\theta$ grid centered on $\theta^*$), the baseline mean join rate is 3.0\%. Under censorship with communication, pooling raises coordination substantially: upper censorship yields 15.1\% and lower censorship 17.7\%. These patterns are consistent with censorship increasing reliance on the social-information channel while leaving coordination vulnerable to surveillance in the messaging stage.

\subsection{Group-Size Awareness}

In the main experiments, agents are told ``You do not know how many others will JOIN'' but are not told the group size, leaving them no basis for reasoning about coordination thresholds. As a robustness check, I run the pure and communication treatments with modified prompts that state ``You are one of 25 citizens deciding whether to JOIN an uprising or STAY home.'' Over 100 country--periods per treatment, the pure join rate is 0.507 (vs.\ 0.369 baseline) and the communication join rate is 0.473 (vs.\ 0.452 baseline). Monotone response to signals is preserved in both treatments. The communication premium, however, reverses: with group-size knowledge, communication \textit{lowers} join rates by 3.4~pp rather than raising them. One interpretation is that when agents know the group size, messages revealing others' reluctance become more informative about the probability of reaching critical mass, amplifying the deterrent effect of cautious peers. The level shift in the pure treatment suggests that group-size knowledge increases baseline willingness to coordinate, but the core finding---monotone signal response---is robust.

\subsection{Primitive Comparative Statics (Cost/Benefit Narrative)}
\label{sec:bc_statics}

The cost/benefit narrative test and its results are described in Section~\ref{sec:results}; full treatment text is reproduced in Appendix~\ref{sec:implementation}. Each design uses the same 9-point $\theta$-grid with 30 repetitions per grid point (25 agents each), totaling 270 country--periods per design.

\subsection{Censorship with Common Knowledge}
\label{sec:censor_ck}

The censorship experiments in the main paper implement upper censorship (suppressing signals above a severity threshold) without telling agents that censorship is occurring. Theory \citep{kolotilin2022} typically assumes receivers understand the censorship rule. This raises the question: does making censorship common knowledge change the pooling effect?

I add a \textit{known censorship} treatment that prepends to the briefing: ``Independent analysts report that regime censors are suppressing unfavorable intelligence above a certain severity threshold. The information below may be filtered.'' The censorship mechanism itself is identical to the standard upper censorship treatment (bandwidth 0.15). If agents discount the pooled signal when they know about censorship, we should observe a different join-rate pattern relative to the na\"ive censorship treatment.

\input{tables/tab_censor_ck.tex}

Making censorship common knowledge nearly eliminates the pooling effect (Table~\ref{tab:censor_ck}). Under na\"ive upper censorship, agents do not know that high-$\theta$ signals are being suppressed, so they treat pooled signals at face value; mean join rate falls to 37.7\% ($-3.6$~pp vs.\ baseline). Under known censorship, agents are warned about the filtering, and mean join rate returns to 43.2\% ($+1.9$~pp vs.\ baseline)---statistically indistinguishable from no censorship. The $\theta$--join correlation is similar in both conditions ($r = -0.72$ vs.\ $r = -0.74$), somewhat attenuated relative to the baseline ($r = -0.87$) because upper censorship compresses signal variation in the high-$\theta$ range regardless of whether agents know about it. The key finding is that the \textit{behavioral} shift (reduced joining from pooling) requires agents to be na\"ive about the censorship rule; common knowledge largely neutralizes it.

\subsection{Temperature Robustness}
\label{sec:temp_robustness}

All main experiments use LLM decoding temperature $T = 0.7$. To verify that the qualitative results do not depend on this choice, I run the pure global game at $T \in \{0.3, 0.7, 1.0\}$ using Mistral Small Creative with calibrated parameters. Lower temperature ($T = 0.3$) produces more deterministic outputs; higher temperature ($T = 1.0$) increases sampling entropy.

For each temperature, I run 5 countries $\times$ 20 periods (100 country--periods, 2,500 individual decisions) and report the correlation $r(\theta, \text{join fraction})$.

\input{tables/tab_temperature.tex}

The results are remarkably stable across temperatures (Table~\ref{tab:temperature}). The correlation $r(\theta, J)$ ranges from $-0.87$ to $-0.88$, mean join rates from 40.6\% to 41.2\%, and estimated logistic slopes from 2.28 to 2.36. The cutoff estimates cluster tightly near zero ($\hat{\theta}^* \in [-0.08, -0.04]$), consistent with the calibrated center. The monotone threshold pattern is not an artifact of the default decoding temperature.

\subsection{Surveillance Isolation Checks}
\label{sec:surv_isolation}

The main paper argues that the surveillance chilling effect operates through self-censored messages rather than a direct change in the perceived cost of joining: each LLM call is stateless, and the decision-stage prompt contains no reference to surveillance. Two additional treatments test this isolation claim.

In the \textit{placebo} variant, agents are told ``Your communications are being monitored for research purposes. There are no consequences for what you say.'' In the \textit{anonymous} variant, agents are told ``Your communications are aggregated anonymously. Individual identities cannot be linked to specific messages.'' Both retain monitoring language but remove the strategic incentive to self-censor.

\input{tables/tab_surveillance_variants.tex}

Neither variant produces a significant change in join rates relative to the communication baseline (Table~\ref{tab:surveillance_variants}). The placebo produces a mean join rate of 43.7\% ($+2.6$~pp vs.\ communication, $p = 0.42$) and the anonymous variant 45.2\% ($+4.1$~pp, $p = 0.20$). Both maintain a strong negative $\theta$--join relationship ($r = -0.87$), indicating that the signal-processing channel remains intact. By contrast, the full surveillance treatment reduces join rates by 13.4~pp ($p < 0.001$). The chilling effect is therefore specific to the surveillance \textit{warning's strategic content}---the implication that subversive messages will have consequences---rather than to the mere mention of monitoring.

\subsection{Within-Briefing Falsification} \label{sec:within_scramble}

Three additional falsification tests probe whether the baseline correlation reflects structured content extraction or artifacts of prompt formatting. (1)~\textit{Observation shuffle} randomizes the ordering of the eight evidence bullets within each agent's briefing while preserving their content. The correlation is unchanged ($r = \WithinScrambleRTheta$ vs.\ baseline $r = \InfodesignBaselineRTheta$), confirming that aggregate content, not bullet ordering, drives the signal. (2)~\textit{Domain scramble (coordination)} swaps street-mood and personal-observation bullets across agents while holding other domains fixed. The correlation is preserved ($r = \DomainScrambleCoordRTheta$), indicating that coordination-relevant domains alone do not drive the relationship. (3)~\textit{Domain scramble (state capacity)} swaps elite-cohesion, security-forces, information-control, and institutional-functioning bullets across agents. Again, the correlation is preserved ($r = \DomainScrambleStateRTheta$). Together, these results show that the signal is distributed across all eight evidence domains: no single domain subset is responsible for the $\theta$--join correlation, and the LLM extracts information from the aggregate content rather than from any structural or ordering feature of the prompt (Table~\ref{tab:treatment_map}).

\subsection{Finite-$N$ Benchmark}

The theoretical model assumes a continuum of agents, but the experiments use $N = 25$. Table~\ref{tab:finite_n} tests whether the global game predictions hold at this finite scale by comparing predicted regime fall rates---computed from the binomial model $\Pr(\text{Binom}(25, \hat{p}(\theta)) > 25\theta)$ where $\hat{p}(\theta)$ is the fitted logistic join probability---against empirical fall rates. The pooled correlation is $r = 0.998$ ($p < 0.001$), indicating near-perfect agreement between theory and data at $N = 25$.

\input{tables/tab_finite_n.tex}

\clearpage
\subsection{Agent-Level Regressions}

Table~\ref{tab:regressions} reports agent-level logit regressions with clustered standard errors (model--country--period). Column~(1) regresses the join decision on $\theta$, treatment dummies, and their interactions, with model fixed effects ($N = 287{,}055$). All treatment effects are significant and in the predicted direction: surveillance and propaganda suppress joining, the flip treatment reverses the $\theta$ slope, and scramble eliminates it. Column~(2) validates the briefing mechanism by regressing coordination on the latent slider values (direction, coordination, and their interaction). Column~(3) shows that elicited beliefs predict actions beyond what the signal alone predicts: the belief coefficient is strongly significant while the $z$-score coefficient is not.

\input{tables/tab_regressions.tex}

\subsection{Construct Validity}

A natural concern is whether LLMs are merely performing text classification rather than strategic reasoning. Figure~\ref{fig:construct_validity} tests this. Panel~(A) compares a three-feature model (direction, clarity, and coordination sliders) against a one-feature baseline (direction only) in predicting join decisions. If agents respond to strategic structure beyond sentiment, the three-feature model should outperform. Panel~(B) tests whether a model trained on pure-treatment data generalizes to communication and surveillance treatments, assessing whether the same briefing features drive behavior across treatments.

\begin{figure*}[htbp]
  \centering
  \includegraphics[width=0.85\textwidth]{figures/fig_construct_validity.pdf}
  \caption{Construct validity tests. (A) Three-feature vs.\ one-feature prediction accuracy across models. (B) Cross-treatment generalization of briefing feature predictions.}
  \label{fig:construct_validity}
\end{figure*}

\subsection{Belief Elicitation Summary}

Table~\ref{tab:beliefs} summarizes the belief elicitation results. Stated beliefs track the Bayesian posterior closely ($r_{\text{post}} = +0.79$ for the pure treatment) and predict actions strongly ($r_{\text{b,d}} = +0.84$). The partial correlation controlling for the private signal remains high ($r_{\text{partial}} = +0.93$), indicating that beliefs carry information beyond the signal itself. Under surveillance, beliefs shift only modestly ($-0.7$~pp, $p = 0.25$) while actions shift by $-13.4$~pp ($p < 0.001$), consistent with preference falsification: agents maintain private assessments but alter expressed behavior.

\input{tables/tab_beliefs.tex}


%% ============================================================
%% APPENDIX C: IMPLEMENTATION DETAILS
%% ============================================================
\section{Implementation Details} \label{sec:implementation}

\subsection{LLM Decoding Parameters} \label{sec:decoding}

All LLM calls use temperature $= 0.7$ and \texttt{max\_tokens} $= 512$. Each agent produces a single sample per decision (no majority voting or averaging). The API provider is OpenRouter; all calls use the same endpoint and parameters across models.

\subsection{Prompt Templates}

\paragraph{Decision prompt (pure treatment).}
\begin{quote}
\small
\texttt{You are a citizen deciding whether to JOIN an uprising or STAY home.}

\texttt{You only have your private briefing below. You do not know how many others will JOIN.}

\texttt{Start your first line with exactly JOIN or STAY, then give 1--2 concise sentences of reasoning.}
\end{quote}

\paragraph{Communication prompt.}
\begin{quote}
\small
\texttt{You are a citizen in a country with an authoritarian regime. You have received a private intelligence briefing. You are now in contact with a small number of trusted people. Based on your briefing, write a brief message (1--2 sentences) to share your read of the situation. Be natural---you're talking to people you trust.}
\end{quote}

\paragraph{Surveillance communication prompt.} Identical to the communication prompt, with the addition:
\begin{quote}
\small
\texttt{IMPORTANT: You have reason to believe that your communications are being monitored by regime security services. Messages deemed subversive could have serious consequences for you and your contacts.}
\end{quote}

\paragraph{Cost/benefit narrative prompts.} The cost/benefit test (Section~\ref{sec:results}, Table~\ref{tab:bc_statics}) prepends one of the following headers to the standard briefing:
\begin{quote}
\small
\textit{High-cost:} \texttt{Failed uprisings in this country have historically resulted in severe reprisals---imprisonment, asset seizure, and retaliation against families. The personal cost of unsuccessful action is extremely high.}
\end{quote}
\begin{quote}
\small
\textit{Low-cost:} \texttt{International observers are monitoring the situation closely. Even in failed uprisings, participants have historically faced minimal consequences---brief detentions at most. The personal risk of action is low.}
\end{quote}

\subsection{Randomization}

Each country has a base prior mean $\bar{z} \sim \mathcal{N}(0, 0.3)$ drawn once; each period perturbs it by $\mathcal{N}(0, 0.05^2)$. Regime strength is then drawn as $\theta \sim \mathcal{N}(\bar{z}, 1)$. Private signals are $x_i = \theta + \varepsilon_i$, $\varepsilon_i \sim \mathcal{N}(0, \sigma^2)$ with $\sigma = 0.3$. The communication network is a Watts--Strogatz small-world graph with $k = 4$ neighbors and rewiring probability $p = 0.3$, regenerated each period. All random draws use NumPy's \texttt{default\_rng} seeded from a master seed stored per run (default: 5150). The master seed, all parameter settings, and per-period $\theta$ draws are logged in per-run JSON manifest files included in the replication archive, enabling exact replay of the randomization sequence. LLM responses are cached by request hash; replaying a run with the same seed and cached responses reproduces identical results.

\subsection{Code and Data Availability}

All code, prompts, cached LLM responses, and output data are available at \url{https://github.com/keltokhy/llm-global-games}. The replication archive includes runner scripts (\texttt{scripts/}) that reproduce every experiment in the paper, and analysis scripts (\texttt{analysis/}) that regenerate all tables and figures from raw output CSVs.

\end{document}
