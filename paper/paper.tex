\documentclass[10pt,twocolumn]{article}
\usepackage{amssymb,amsmath,amsthm}
\usepackage[margin=0.75in]{geometry}
\usepackage{microtype}
\usepackage[hidelinks]{hyperref}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{float}
\usepackage{placeins}
\usepackage[round]{natbib}
\usepackage{xcolor}
\usepackage{subcaption}
\usepackage{multirow}

\newtheorem{proposition}{Proposition}
\newtheorem{hypothesis}{Hypothesis}
\newtheorem{result}{Result}

\urlstyle{same}
\interfootnotelinepenalty=10000

\title{LLMs Can Play (Global) Games}

\author{
  Khaled Eltokhy \\
  Department of Economics \\
  The Graduate Center, CUNY
}
\date{February 2026}

\begin{document}

\maketitle

\begin{abstract}
I embed nine large language models in the Morris--Shin (2003) regime change game, conveying private signals as natural-language intelligence briefings. Across 1,800 country--periods (45,000 individual decisions), join rates exhibit monotone threshold behavior consistent with the equilibrium comparative statics (mean $r = +0.73$, $p < 0.001$ for every model); scrambling briefings collapses the correlation ($r = +0.23$) and inverting signals flips it ($r = -0.67$). Taking this as a platform, I study how authoritarian regimes exploit the same information channel that makes coordination possible. Communication introduces strategic uncertainty without raising coordination: the pooled effect on join rates is small and not statistically significant, yet the channel it opens is exploitable. Surveillance poisons the channel through preference falsification---agents maintain private beliefs but self-censor, pushing join rates well below the communication baseline ($-11.1$~pp on average across three architectures). Censorship eliminates it: combining surveillance with upper censorship collapses coordination from 30.9\% to 3.7\%. The regime does not need to change what citizens believe; it needs only to make them uncertain about each other.
\end{abstract}


%% ============================================================
%% 1. INTRODUCTION
%% ============================================================
\section{Introduction}

Coordination games with multiple equilibria are central to the analysis of bank runs \citep{diamond1983}, currency attacks \citep{obstfeld1996}, and political upheaval \citep{angeletos2007a}. The theory of global games \citep{carlsson1993, morris2003, frankel03} resolves the multiplicity by introducing private information: when agents observe noisy private signals about an underlying fundamental, a unique equilibrium emerges in threshold strategies. The canonical application---regime change---has been extensively studied theoretically. Laboratory experiments have tested the theory in simplified settings: small groups with numeric signals and stylized payoffs \citep{heinemann2004, heinemann2009, szkup2020}. But the full Morris--Shin regime change game---continuous private signals, large groups, strategic uncertainty---has not been implemented experimentally. Field data from actual crises confounds strategic behavior with institutional and informational heterogeneity.

I take a different approach: I embed large language model (LLM) agents directly in the \citet{morris2003} regime change game. Each agent receives a private signal $x_i = \theta + \varepsilon_i$, translated into a natural-language intelligence briefing describing the political, economic, and security situation. No explicit payoff table is provided---the stakes of joining or staying are embedded in the narrative, forcing agents to extract strategic information from language rather than from a formatted matrix. I run this experiment across nine architecturally distinct models spanning six families (Mistral, Llama, Qwen, OLMo, GPT, and MiniMax), with 25 agents per country--period and pure-treatment sample sizes of 100--800 country--periods per model (Table~\ref{tab:models}), totaling 1,800 country--periods (45,000 individual decisions) in the pure treatment alone.

The first finding is that LLM agents exhibit stable, monotone threshold behavior consistent with the equilibrium prediction. The correlation between the theoretical attack mass $A(\theta) = \Phi[(x^* - \theta)/\sigma]$ and the empirical join fraction averages $r = +0.73$ ($p < 0.001$ for every model). Two falsification tests confirm that this correlation is driven by briefing content rather than incidental features of the prompt: randomly scrambling briefings across periods reduces it to $r = +0.23$, and inverting the signal direction flips it to $r = -0.67$. In both cases the change relative to the pure treatment is significant (Fisher $z$-test, $p < 0.001$). This establishes monotonicity and content sensitivity---necessary conditions for equilibrium play, though not sufficient to establish full Bayesian Nash rationality. Elicited beliefs track the Bayesian posterior ($r = +0.79$) and predict actions beyond what signals alone predict (partial $r = +0.84$), providing evidence of strategic processing beyond mere sentiment following.

The second finding---and the paper's central contribution---is that the information channel is simultaneously the mechanism of coordination and its greatest vulnerability. Pre-play communication does not raise agents' beliefs or their willingness to act (pooled effect $+0.9$~pp, not significant across nine models), yet the channel it opens introduces strategic uncertainty that makes coordination exploitable. Surveillance poisons the channel through preference falsification ($-13.4$~pp for the primary model, $p < 0.001$), censorship eliminates it through pooling ($+18.5$~pp for upper censorship), and their combination collapses coordination from 30.9\% to 3.7\%. Propaganda's behavioral effect saturates quickly while its mechanical effect scales linearly, implying diminishing returns. The regime does not need to change what citizens believe---it needs only to make them uncertain about each other.

The paper makes three contributions. First, it tests whether the threshold equilibrium patterns predicted by global games theory emerge when LLM agents are embedded in the full Morris--Shin regime change game---with continuous private signals, large groups, and narrative information---going beyond the simplified coordination games tested in existing laboratory experiments. Second, it provides the first experimental tests of information design and authoritarian control predictions from \citet{goldstein2016}, \citet{kolotilin2022}, and \citet{edmond2013} in a coordination game, yielding a unified account of how authoritarian regimes exploit the dual nature of communication channels---instruments of coordination that are simultaneously vectors of control. Third, it demonstrates that LLMs can serve as experimental subjects for strategic environments, extending the \citet{horton2023} \textit{homo silicus} methodology beyond $2 \times 2$ games to the continuous-signal, $N$-player coordination games that dominate applied theory.

Section~\ref{sec:literature} reviews the related literature. Section~\ref{sec:model} presents the theoretical framework. Section~\ref{sec:design} describes the experimental design. Section~\ref{sec:results} reports the main results on equilibrium alignment; Section~\ref{sec:falsification} presents the falsification tests. Section~\ref{sec:communication} analyzes pre-play communication. Sections~\ref{sec:infodesign}--\ref{sec:interactions} cover information design, surveillance, propaganda, and their interactions. Appendix~\ref{sec:robustness} reports robustness checks. Section~\ref{sec:conclusion} concludes.


%% ============================================================
%% 2. RELATED LITERATURE
%% ============================================================
\section{Related Literature} \label{sec:literature}

This paper connects five literatures: global games and equilibrium selection, information design and Bayesian persuasion, communication in coordination games, the political economy of authoritarian information control, and the emerging field of LLMs as economic agents.

The theory of global games resolves the equilibrium multiplicity that plagues coordination games by introducing heterogeneous private information. \citet{carlsson1993} showed that adding arbitrarily small noise to a 2$\times$2 coordination game generically selects the risk-dominant equilibrium via iterated dominance. \citet{morris1998} applied this technique to currency crises, demonstrating that heterogeneous private signals about fundamentals deliver a unique threshold equilibrium even in large-player coordination games. \citet{frankel03} generalized the result to $N$-player, multi-action games with strategic complementarities.

The canonical regime change application---in which citizens decide whether to join an uprising against a regime of uncertain strength---was developed by \citet{morris2003}, who established the threshold equilibrium structure I implement experimentally. \citet{angeletos2007a} extended the framework to dynamic settings where agents learn across periods, showing that multiplicity can re-emerge when agents observe whether the regime survived previous rounds. \citet{morris2002} demonstrated that public signals are overweighted in coordination games because they predict others' actions, a finding central to my communication and information design treatments.

Laboratory experiments have tested the theory in stylized settings that necessarily depart from the canonical regime change game. \citet{heinemann2004} ran coordination games with public and private signals, finding that subjects' thresholds match the global game prediction under private information but tilt toward payoff-dominance under common information. \citet{heinemann2009} measured strategic uncertainty directly through certainty equivalents. \citet{shurchkov2013} tested dynamic global games, finding that subjects learn from failed attacks. \citet{szkup2020} elicited beliefs alongside actions, finding that comparative statics of thresholds with respect to signal precision are reversed relative to theory---subjects become more cautious with noisier signals, consistent with level-$k$ thinking rather than Bayesian Nash equilibrium. \citet{helland2021} tested information quality in a regime change game with numeric signals and small groups, confirming the level-$k$ reversal. These experiments share a common limitation: subjects receive numeric signal draws and face stylized payoff tables, compressing the rich information processing that real-world coordination requires into a simple decision problem.

This paper implements the full Morris--Shin regime change game with natural-language private signals and 25-agent groups, going beyond the small-group, numeric-signal designs of existing experiments to test the threshold equilibrium prediction in the canonical application for which it was developed.

\citet{kamenica2011} established the Bayesian persuasion framework: a sender who commits to an information structure can influence a Bayesian receiver's action by shaping the posterior distribution of beliefs. \citet{bergemann2016} unified Bayesian persuasion with correlated equilibrium under the concept of Bayes Correlated Equilibrium. \citet{bergemann2019information} provided a comprehensive survey integrating cheap talk, persuasion, and robust mechanism design.

The application to coordination games is directly relevant. \citet{goldstein2016} applied Bayesian persuasion to the regime change game, showing that a credible commitment to abandon the regime below a threshold functions as an optimal signal. \citet{inostroza2025} solved the optimal public information design problem in a global game with heterogeneous private signals, characterizing when pass/fail structures are optimal. \citet{kolotilin2022} proved that upper censorship---pooling all states above a threshold while revealing below---is optimal for all priors when the sender's marginal utility is quasi-concave. \citet{mathevet2020} characterized the extent to which an information designer can manipulate agents' higher-order beliefs.

My information design experiments implement these theoretical designs computationally within a full-scale coordination game, providing the first experimental test of information design predictions in a global game.

The cheap talk literature---\citet{crawford1982}, \citet{farrell1996}, \citet{blume2007}, \citet{ellingsen2010}---establishes that pre-play communication can improve coordination, with \citet{avoyan2020} testing this in a two-player global game. In real-world coordination, \citet{enikolopov2020} provided causal evidence that social media penetration increases protest incidence. My communication treatment embeds agents in a Watts-Strogatz small-world network and allows natural-language messaging before the coordination decision.

The theoretical literature on authoritarian information control builds directly on the global games framework. \citet{edmond2013} embedded costly propaganda into the Morris--Shin regime change game. \citet{kuran1991} provides the foundational theory of preference falsification---the systematic misrepresentation of political preferences under social pressure. Empirical work documents that Chinese censorship targets content with collective action potential \citep{king2013}, that surveillance awareness suppresses expression \citep{penney2016, stoycheff2016}, and that pro-regime propaganda reduces protest probability \citep{carter2021}. My surveillance and propaganda treatments directly test these mechanisms within the full regime change game---an environment difficult to implement with human subjects at scale.

\citet{horton2023} proposed treating LLMs as ``homo silicus''---computational models of human decision-makers. Subsequent work has tested LLMs in game-theoretic settings: \citet{akata2025} found that LLMs perform well in self-interested games but struggle in coordination games; \citet{petrov2025} evaluated 22 LLMs on a behavioral game theory battery, finding that model scale alone does not predict strategic performance; \citet{sun2025survey} identify coordination games as a consistent failure mode. The alignment literature motivates my design: \citet{huang2024} and \citet{carlini2025} document that ethical alignment and chatbot fine-tuning shift risk preferences and amplify omission bias, which is why I convey strategic stakes through narrative rather than explicit payoff tables. Critical reviews by \citet{gao2025} and \citet{grossmann2025} warn that validation remains poorly addressed in LLM-based agent simulations.

No existing paper places LLM agents in a Morris--Shin global game---the specific game form where private noisy signals about an underlying state variable determine a threshold equilibrium. I provide the first such implementation, and extend it to information design, surveillance, and propaganda.


%% ============================================================
%% 3. THEORETICAL FRAMEWORK
%% ============================================================
\section{The Global Game of Regime Change} \label{sec:model}

A continuum of citizens indexed by $i \in [0,1]$ simultaneously choose whether to join an uprising ($a_i = 1$) or stay home ($a_i = 0$). The regime has strength $\theta \in \mathbb{R}$, drawn from a diffuse (improper uniform) prior. States $\theta \leq 0$ represent regimes so weak they fall without opposition; states $\theta \geq 1$ represent regimes that survive even unanimous attack. The regime falls if the mass of citizens who join exceeds $\theta$:
\begin{equation}
    \text{Regime falls} \iff A \equiv \int_0^1 a_i \, di > \theta.
\end{equation}

Payoffs depend on the citizen's action and the outcome:
\begin{equation}
    u_i(a_i, A, \theta) = \begin{cases}
        B & \text{if } a_i = 1 \text{ and } A > \theta \\
        -C & \text{if } a_i = 1 \text{ and } A \leq \theta \\
        0 & \text{if } a_i = 0
    \end{cases}
\end{equation}
where $B > 0$ is the payoff to joining a successful uprising and $C > 0$ is the cost of joining a failed attempt. Non-participants receive zero regardless of the outcome.

Each citizen observes a private signal $x_i = \theta + \varepsilon_i$, where $\varepsilon_i \sim \mathcal{N}(0, \sigma^2)$ independently across citizens.

\begin{proposition}[Morris and Shin, 2003]
In the limit of diffuse priors, there exists a unique Bayesian Nash equilibrium in threshold strategies. An agent joins if and only if $x_i < x^*$, where
\begin{equation}
    x^* = \theta^* + \sigma \Phi^{-1}(\theta^*)
\end{equation}
and $\theta^* = B/(B+C)$.
\end{proposition}

The \textit{attack mass}---the fraction of the population that joins at regime strength $\theta$---is:
\begin{equation} \label{eq:attack_mass}
    A(\theta) = \Phi\!\left(\frac{x^* - \theta}{\sigma}\right).
\end{equation}

This is a decreasing function of $\theta$: weaker regimes face larger uprisings.

An information designer controls the mapping $\pi: \Theta \to \Delta(\mathcal{S})$ from states to signal distributions, but cannot control agents' actions. In my implementation, $\pi$ is the function mapping regime strength $\theta$ to the parameters of the briefing generator---a deterministic system that produces a natural-language intelligence briefing from a z-score derived from the agent's private signal.

The briefing generator has three control parameters: clarity (the width of the Gaussian kernel mapping z-scores to text, where wider kernels produce more ambiguous briefings), directional precision (the slope of the mapping from z-score to briefing sentiment, where steeper slopes produce more accurate signal reflection), and dissent framing (the floor on the probability that the briefing includes language about public discontent).

The designer concentrates manipulation near $\theta^*$ using a Gaussian proximity weight:
\begin{equation}
    w(\theta) = \exp\!\left(-\left(\frac{\theta - \theta^*}{\text{bandwidth}}\right)^2\right)
\end{equation}
where $\text{bandwidth} = 0.15$ in the baseline specification.

The framework generates testable predictions for both the baseline game and information design.

\begin{hypothesis}[Equilibrium Alignment] \label{hyp:alignment}
The empirical join fraction should be positively correlated with the theoretical attack mass $A(\theta)$.
\end{hypothesis}

\begin{hypothesis}[Signal Dependence] \label{hyp:scramble}
The correlation in Hypothesis~\ref{hyp:alignment} should collapse when the mapping from $\theta$ to briefing content is broken (scramble test).
\end{hypothesis}

\begin{hypothesis}[Signal Direction] \label{hyp:flip}
The correlation should invert when signals are flipped.
\end{hypothesis}

\begin{hypothesis}[Communication Effect] \label{hyp:comm}
Pre-play communication should increase join rates, with the effect strongest near $\theta^*$ where strategic uncertainty is highest.
\end{hypothesis}

\begin{hypothesis}[Stability Design] \label{hyp:stability}
Increasing ambiguity and mixed evidence near $\theta^*$ should flatten the $\theta$--join relationship and induce pooling.
\end{hypothesis}

\begin{hypothesis}[Upper Censorship] \label{hyp:censor}
Upper censorship should raise join rates in censored states by creating pooling \citep{kolotilin2022}.
\end{hypothesis}

\begin{hypothesis}[Surveillance Chilling Effect] \label{hyp:surveillance}
Informing agents that communications are monitored should reduce coordination \citep{kuran1991}.
\end{hypothesis}

\begin{hypothesis}[Propaganda Dose-Response] \label{hyp:propaganda}
Regime plant agents transmitting pro-regime messages should suppress coordination, with the effect increasing in the number of plants \citep{edmond2013}.
\end{hypothesis}


%% ============================================================
%% 4. EXPERIMENTAL DESIGN
%% ============================================================
\section{Experimental Design} \label{sec:design}

The experiment has two parts. Part~I tests whether LLM agents play the global game: a pure treatment (private signals only), a communication treatment (pre-play messaging), and falsification tests. Part~II takes the behavioral foundation as given and studies information design: stability/instability designs, censorship, single-channel decomposition, surveillance, and propaganda. All LLM interactions use the same prompt structure across models.

For each country--period, nature draws $\theta \sim \mathcal{N}(\bar{z}, 1)$, where $\bar{z}$ is a public prior mean drawn randomly for each country. Each agent $i$ receives a private signal $x_i = \theta + \varepsilon_i$ and computes a z-score $z_i = (x_i - \bar{z})/\sigma$. Because agents observe only their private briefing and never the prior distribution or its parameters, the diffuse-prior equilibrium formula (Proposition~1) serves as the relevant benchmark. The z-score is then translated into a multi-paragraph intelligence briefing by a deterministic generator that maps signal strength to narrative content about regime stability, economic conditions, public sentiment, and coordination prospects.

The briefing rendering is calibrated once per model using a separate z-score sweep to ensure that join probability is monotone in $z$ and roughly centered near the cutoff. Calibration adjusts a single parameter---the cutoff center---via a damped iterative procedure that shifts the center until the fitted logistic is approximately zero-centered. The sigmoid shape (its slope and curvature) is emergent from the LLM's own response pattern and is never optimized or penalized. Holdout validation (30\% of z-grid points withheld) suggests no overfitting: holdout RMSE (0.112) is comparable to training RMSE (0.131). Calibration does not use $\theta$ draws or any global-game outcome data, and all reported treatments and falsification tests hold calibrated parameters fixed. Importantly, calibration centers the response function but does not create it: a model that produced random or flat responses to briefing content would show no monotone pattern regardless of calibration. The sigmoid shape and its slope are emergent properties of the model's language understanding.

Each agent receives a system prompt identifying them as a citizen deciding whether to JOIN or STAY, followed by their intelligence briefing. No explicit payoff table is provided---the stakes are conveyed entirely through the narrative.

This design choice is substantive. In preliminary experiments, providing an explicit payoff table caused sophisticated models to short-circuit the information-processing channel: they computed the optimal strategy from the table and ignored briefing content, producing flat join rates uncorrelated with regime strength. The no-payoff-table design forces agents to form beliefs from the narrative, mirroring how real citizens process political information from news and rumors rather than from a formatted decision matrix.

Part~I has four treatments. In the \textit{pure global game}, each agent decides independently based on their private briefing. In the \textit{communication} treatment, agents send a message to a small network of ``trusted contacts'' (Watts-Strogatz small-world network, $k=4$, $p=0.3$) before deciding, with access to both their briefing and received messages. Two falsification tests break the signal channel: in \textit{scramble}, all briefings across periods within a country are pooled and randomly redistributed; in \textit{flip}, the z-score is negated before briefing generation, so agents who should see weak-regime cues receive strong-regime cues and vice versa.

Part~II implements information designs. Design names refer to the \textit{regime's} objective, not the equilibrium outcome: the ``stability'' design is the information structure a stability-seeking regime would implement. The \textit{stability-maximizing} design multiplies clarity width by 4, raises the dissent floor to 0.45, and flattens the directional slope by a factor of 0.25 near $\theta^*$. The \textit{instability-maximizing} design does the opposite: clarity width is multiplied by 0.15, the dissent floor is lowered to 0.05, and the directional slope is steepened by a factor of 3. \textit{Public signal injection} appends a shared ``news bulletin'' generated from $\theta$ with 4 observations to each agent's private briefing, creating a common-knowledge channel. \textit{Upper censorship} pools states above $\theta^*$ so agents receive an identical censored briefing, while fully revealing states below $\theta^*$ \citep{kolotilin2022}; \textit{lower censorship} is the mirror image. The \textit{surveillance} treatment augments the communication prompt with a warning that communications are being monitored by regime security services. \textit{Propaganda} introduces regime plant agents ($k = 2, 5, 10$) who participate in the communication network but transmit fixed pro-regime messages and always STAY.

\input{tables/tab_models.tex}

I test nine architecturally distinct models spanning six architecture families (Table~\ref{tab:models}). Models range from 3 billion to 235 billion parameters, including both dense architectures (Llama, Mistral, OLMo) and mixture-of-experts (Qwen). All experiments use $N = 25$ agents per country--period and $\sigma = 0.3$, with sample sizes varying by model and treatment as reported in Table~\ref{tab:models}. I vary $B$ and $C$ such that $\theta^* = B/(B+C)$ has a mean of approximately 0.45 across periods. All LLM calls use temperature $= 0.7$ with a single sample per decision---no majority voting or averaging---so each of the 45,000 individual decisions reflects one stochastic draw from the model's conditional distribution (see the online appendix for full decoding parameters).

For the information design experiments, I fix $B = C = 1$ (so $\theta^* = 0.50$) and a grid of 9 values of $\theta$ spanning $[\theta^* - 0.30, \theta^* + 0.30] = [0.20, 0.80]$, running repeated country--periods per $(\text{design}, \theta)$ cell with 25 agents each. Baseline, stability, censorship, scramble, and flip use 30 repetitions per cell (270 observations per design). Instability and public signal use 60 repetitions per cell (540 observations). Single-channel decomposition uses 10 repetitions per cell (90 observations) for each channel. The primary model is Mistral Small Creative. Cross-model replication uses six additional models.


%% ============================================================
%% 5. RESULTS: PURE GLOBAL GAME
%% ============================================================
\section{Do LLM Agents Play the Global Game?} \label{sec:results}

\begin{figure}[t]
  \centering
  \includegraphics[width=\columnwidth]{figures/fig01_sigmoid.pdf}
  \caption{Empirical join fraction vs.\ regime strength $\theta$ (Mistral Small Creative, 800 country--periods). Grey points show binned means with 95\% CIs; solid line is the fitted logistic. Dashed red: theoretical attack mass $A(\theta)$. The empirical sigmoid is shifted leftward ($\hat{\theta}^* = -0.37$) relative to the theoretical threshold ($\theta^* = 0.50$), reflecting the attenuation and baseline action bias discussed in the text. Cross-model results in Table~\ref{tab:main_results} (mean $r = +0.73$, all nine significant at $p < 0.001$).}
  \label{fig:sigmoid}
\end{figure}

\begin{result}[Equilibrium Alignment]
Across nine models and 1,800 country--periods in the pure global game treatment, the Pearson correlation between the empirical join fraction and the theoretical attack mass $A(\theta)$ averages $r = +0.73$ ($p < 0.001$ for every model).
\end{result}

Table~\ref{tab:main_results} reports results by model. Correlations range from $r = +0.65$ (OLMo 3 7B) to $r = +0.84$ (Trinity Large), with the pooled correlation at $r = +0.67$---lower than any individual model's because heterogeneous mean join rates across models add noise when pooling. The pooled OLS regression yields:
\begin{equation}
    J = 0.17 + 0.52\,A(\theta), \quad R^2 = 0.45.
\end{equation}

The slope of 0.52 indicates that LLM agents respond to the theoretical attack mass at roughly half the predicted rate---an attenuation expected when agents process narrative rather than numeric signals, since the briefing-to-belief mapping introduces noise that biases the slope toward zero (classical measurement error attenuation). The intercept of 0.17 reflects a baseline propensity to join even when the equilibrium predicts near-zero participation, driven in part by high-action models such as OLMo 3 7B (mean join rate 0.72).\footnote{Country-period observations within a model share calibration parameters and prompt structure, raising the possibility that standard errors understate uncertainty. Clustering standard errors by country inflates the OLS slope SE from 0.014 to 0.050 but preserves significance ($p < 10^{-25}$). Clustering by model yields SE $= 0.033$ ($p < 10^{-55}$). All nine per-model correlations remain significant at $p < 0.001$ under country-clustered inference.}

\input{tables/tab_main_results.tex}

The mean join rate across all models is 0.47, slightly below the theoretical mean. OLMo 3 7B stands out with a mean join rate of 0.72---a substantial action bias---yet it still produces a significant positive correlation ($r = +0.65$, $p < 0.001$), indicating that even a model biased toward joining responds to the direction of the signal.

\begin{figure}[t]
  \centering
  \includegraphics[width=\columnwidth]{figures/fig02_cross_model.pdf}
  \caption{Cross-model summary of signal monotonicity. Points report $|r(\theta,\ \mathrm{join})|$ under pure and communication; $x$ markers (if any) indicate models where scrambling does not collapse the correlation ($|r|>0.3$).}
  \label{fig:cross_model}
\end{figure}

The alignment is stable across architectures: correlations span $r \in [0.65, 0.84]$ despite parameter counts ranging from 3B to 235B (Table~\ref{tab:main_results}). Mean join rates vary---from 0.38 (Mistral) to 0.72 (OLMo)---reflecting model-specific action biases that shift the intercept but not the slope or correlation. In the language of the global games model, different LLMs implement different cutoff strategies, but all respond monotonically to the underlying signal.

The positive correlation with $A(\theta)$ confirms that LLM behavior is monotone in the signal and sensitive to briefing content---necessary conditions for equilibrium play. Whether this reflects full Bayesian Nash rationality or a simpler heuristic that happens to track the equilibrium prediction is a harder question. Three pieces of evidence bear on this. First, the LLM's join curve is substantially steeper than a naive text-sentiment predictor (logistic slope 1.78 vs.\ the gradual text baseline; $r = 0.80$), suggesting processing beyond surface sentiment (Section~\ref{sec:falsification}). Second, the scramble and flip tests confirm that the correlation is driven by content, not by incidental features of the prompt. Third, belief elicitation reveals that agents form expectations tracking the Bayesian posterior ($r = +0.78$) and predict actions beyond what signals alone explain (partial $r = +0.93$), consistent with strategic reasoning about others' likely behavior. Taken together, the evidence supports the conclusion that LLMs implement stable, threshold-like monotone policies that respond systematically to the information environment. I use ``equilibrium alignment'' as shorthand for this behavioral pattern throughout, without claiming that agents compute or approximate the Bayesian Nash equilibrium in the decision-theoretic sense.


%% ============================================================
%% 6. FALSIFICATION
%% ============================================================
\section{Falsification Tests} \label{sec:falsification}

The positive correlation documented in Section~\ref{sec:results} admits an alternative explanation: LLM agents might simply produce stereotyped responses that happen to correlate with regime strength for reasons unrelated to the briefing content. The scramble and flip tests discriminate between this alternative and genuine signal extraction.

\begin{result}[Signal Dependence]
Cross-period scrambling of briefings reduces the mean correlation from $r = +0.73$ to $r = +0.23$ across eight models. The pooled correlation drops from $r = +0.67$ to $r = +0.10$ (Fisher $z = 18.59$, $p < 0.001$).
\end{result}

The scramble preserves the marginal distribution of briefing content but breaks the mapping from each period's $\theta$ to the signals agents receive. The residual positive correlation ($+0.23$ mean, $+0.10$ pooled) is small relative to the baseline and varies across models ($-0.13$ to $+0.42$), consistent with noise in finite samples.

\begin{result}[Signal Direction]
Inverting the signal direction flips the mean correlation from $r = +0.73$ to $r = -0.67$ across eight models. The pooled correlation moves from $r = +0.67$ to $r = -0.63$ (Fisher $z = 40.76$, $p < 0.001$).
\end{result}

The flip negates the z-score before briefing generation, producing a near-symmetric reversal ($+0.73 \to -0.67$). This makes it unlikely that the baseline correlation reflects structural features of the prompt or model-specific tendencies.

\begin{figure*}[t]
  \centering
  \includegraphics[width=\textwidth]{figures/fig03_falsification.pdf}
  \caption{Falsification triptych. \textit{Left:} Pure global game (mean $r = +0.73$). \textit{Center:} Cross-period scramble breaks the $\theta$-to-briefing mapping (mean $r = +0.23$). \textit{Right:} Signal flip inverts the mapping (mean $r = -0.67$). Each panel pools data from models with full falsification suites.}
  \label{fig:falsification}
\end{figure*}

The pure $\to$ scramble $\to$ flip pattern replicates across all eight models with full falsification suites. Reporting $(r_{\text{pure}}, r_{\text{scramble}}, r_{\text{flip}})$: Mistral Small Creative $(+0.67, +0.42, -0.62)$, Llama 3.3 70B $(+0.79, +0.33, -0.73)$, OLMo 3 7B $(+0.65, +0.14, -0.56)$, Ministral 3B $(+0.79, +0.30, -0.74)$, Qwen3 30B $(+0.78, +0.32, -0.71)$, GPT-OSS 120B $(+0.70, -0.13, -0.64)$, Trinity Large $(+0.84, +0.32, -0.70)$, and MiniMax M2-Her $(+0.66, +0.14, -0.69)$. Every model shows strong positive correlation under pure, collapse under scramble, and sign reversal under flip.

The briefing generator maps z-scores monotonically to text---could a model that simply reads briefing sentiment, without any strategic reasoning, produce the observed sigmoid? To test this, I construct the simplest possible text-only predictor.

The generator assigns each briefing an internal \textit{direction} score $d \in [0,1]$, where $d = 1$ indicates regime-favorable language. A naive baseline predicts $\hat{p}_{\text{join}} = 1 - d$: join whenever the text sounds bad for the regime. This is the prediction a pure sentiment reader would make.

The correlation between this baseline and actual LLM decisions is $r = 0.80$---confirming that the text carries signal (as designed, since briefings are constructed to convey z-score content). However, the LLM's empirical join curve is substantially steeper than the text baseline (Figure~\ref{fig:text_baseline}). The fitted logistic has slope 1.78, producing a sharp transition around $z = 0$, while the text baseline drifts gradually from $\approx 0.93$ to $\approx 0.10$ across the full z-score range. The encoder is essentially monotone ($r(z, d) = 0.995$).

The gap between the text baseline and the empirical sigmoid indicates that the LLM sharpens the signal beyond surface sentiment, producing threshold-like behavior rather than linearly tracking the briefing's tone. This is consistent with---though does not prove---strategic information processing.

\begin{figure}[t]
  \centering
  \includegraphics[width=\columnwidth]{figures/fig15_text_baseline.pdf}
  \caption{Text baseline identification test. Blue: empirical LLM join rate across z-scores. Orange: naive text-only predictor ($1 - \text{direction}$, $r = 0.80$). Red: fitted logistic (slope = 1.78). The LLM produces a steeper transition than the text baseline, indicating processing beyond sentiment reading. Mistral Small Creative, 210 observations.}
  \label{fig:text_baseline}
\end{figure}

A stronger test asks whether agents form beliefs about others' behavior consistent with the equilibrium prediction. After each decision, I elicit stated beliefs by asking agents: ``On a scale from 0 to 100, how likely do you think the uprising will succeed?'' I run this elicitation under three treatments---pure, communication, and surveillance---each with 200 country--periods (${\approx}\,5{,}000$ agent-level observations per treatment). In the pure treatment, stated beliefs correlate strongly with the Bayesian posterior $P(\text{success} \mid x_i) = \Phi[(\theta^* - x_i)/\sigma]$ ($r = +0.79$, $p < 0.001$; Figure~\ref{fig:beliefs}a). Beliefs track the posterior with systematic underconfidence (slope $< 1$), but the direction and rank ordering are preserved. The pattern holds across treatments: $r = +0.79$ under communication and $r = +0.78$ under surveillance.

Actions are strongly monotone in stated beliefs ($r = +0.84$ in pure, $+0.83$ in communication, $+0.73$ in surveillance). The join rate as a function of belief is steep in the pure treatment: agents with beliefs below 40\% rarely join, while those above 80\% almost always join. The notably lower belief--action correlation under surveillance ($r = +0.73$ vs.\ $+0.84$ under pure) is itself evidence of preference falsification: surveillance disrupts the link between private beliefs and public actions. Communication leaves mean beliefs unchanged relative to pure ($44.4\%$ vs.\ $44.4\%$, $\Delta = 0.0$~pp) and has a negligible effect on join rates in this sample ($-0.6$~pp). The nine-model pooled effect on join rates is $+0.9$~pp (Section~\ref{sec:communication}), small and not statistically significant; the sign varies across models, consistent with the communication channel introducing strategic uncertainty rather than uniformly promoting coordination. Crucially, beliefs predict decisions beyond what the signal alone predicts: the belief--action correlation ($r = +0.84$) substantially exceeds what surface sentiment alone would produce (the text baseline achieves $r = 0.80$). This pattern is consistent with strategic reasoning about others' likely actions.\footnote{The belief elicitation data is from a single model (Mistral Small Creative). However, the behavioral patterns that belief data explains---the surveillance chilling effect and the communication--action gap---replicate across three architectures (Mistral, Llama, Qwen3), suggesting the underlying mechanism generalizes beyond the model for which beliefs were directly measured.}

\begin{figure*}[t]
  \centering
  \includegraphics[width=\textwidth]{figures/fig16_beliefs.pdf}
  \caption{Belief elicitation results (Mistral Small Creative, 200 country--periods per treatment, ${\approx}\,5{,}000$ agent observations each). \textit{Left:} Stated beliefs track the Bayesian posterior $P(\text{success} \mid x_i)$ with $r = +0.78$ and systematic underconfidence (slope $= 0.63$). Dashed line: perfect calibration. \textit{Right:} Join rate by stated belief bin under four treatments. Agents with 60--80\% beliefs join at 98\% in the pure treatment but only 57--61\% under communication, surveillance, and propaganda ($k{=}5$). Propaganda preserves the belief--posterior correlation ($r = +0.78$, identical to pure) while suppressing actions---consistent with a mechanical rather than belief-based channel.}
  \label{fig:beliefs}
\end{figure*}

Second-order beliefs---agents' predictions about \textit{others'} join rates---provide a sharper test of strategic reasoning. I elicit these by asking each agent: ``Out of 100 citizens in a similar situation, how many do you think would choose to JOIN?'' Across 200 country--periods per treatment (${\approx}\,5{,}000$ agent observations each), second-order beliefs track the private signal ($r = -0.73$, $p < 0.001$) and vary monotonically with regime strength, consistent with agents reasoning about others' likely responses to correlated signals (Figure~\ref{fig:second_order_beliefs}). Crucially, surveillance does \textit{not} shift second-order beliefs (mean $31.2\% \to 30.9\%$, $\Delta = -0.3$~pp, $p = 0.59$) but \textit{does} shift behavior ($-13.4$~pp). The result is a belief--behavior gap that \textit{reverses direction} across treatments: in the pure treatment, agents predict $31\%$ will join but $42\%$ actually do (underprediction); under surveillance, agents still predict $31\%$ but only $28.5\%$ actually do (slight overprediction). The shift in behavior ($-13.4$~pp) dwarfs the shift in beliefs ($-0.3$~pp), precisely the signature of preference falsification in the sense of \citet{kuran1991}---surveillance changes what agents \textit{do} without changing what they \textit{believe} others would do, because the chilling effect operates through self-censorship rather than through belief updating.

\begin{figure*}[t]
  \centering
  \includegraphics[width=\textwidth]{figures/fig17_second_order_beliefs.pdf}
  \caption{Second-order beliefs (Mistral Small Creative). \textit{Left:} Mean second-order belief---agents' predicted join rate---decreases with regime strength $\theta$ across all treatments, confirming that beliefs track the private signal. Surveillance (purple) overlaps almost exactly with pure (gray), while communication (blue) slightly compresses the range. \textit{Right:} Second-order belief vs.\ actual period-level join rate. Agents are approximately calibrated: the regression lines track the 45-degree perfect-calibration reference (dashed).}
  \label{fig:second_order_beliefs}
\end{figure*}

%% ============================================================
%% 7. COMMUNICATION
%% ============================================================
\section{Communication} \label{sec:communication}

\begin{figure}[t]
  \centering
  \includegraphics[width=\columnwidth]{figures/fig05_communication.pdf}
  \caption{Communication effect by regime strength, pooled across nine models. Communication increases join rates for weak regimes ($\theta < \theta^*$) but has no effect or slightly reduces join rates for strong regimes ($\theta > \theta^*$).}
  \label{fig:communication}
\end{figure}

\begin{result}[Communication has a small, heterogeneous effect]
Pre-play communication raises the mean join rate by 0.9 percentage points, from 0.468 to 0.477, pooled across nine models. The effect is not statistically significant in the pooled sample and varies in sign across models, with the direction concentrated in weak-regime environments.
\end{result}

Agents send a message to their network neighbors and observe received messages before deciding. The effect is heterogeneous across models: six of nine show positive effects ($+0.1$ to $+7.8$~pp), while three show negative effects ($-2.4$ to $-4.6$~pp). The communication premium is not structurally robust: the pooled average is near zero, and its sign depends on model-specific features of information processing. Communication does not change the \textit{correlation} with the theoretical prediction ($r = +0.73$ vs.\ $+0.73$ under pure); it preserves the signal structure while introducing strategic uncertainty about others' actions. The asymmetry across $\theta$ is consistent with passive Bayesian updating: agents update toward joining when neighbors' correlated signals reveal regime weakness, with a floor effect preventing further declines under strong regimes where join rates are already near zero.

The belief elicitation data (Section~\ref{sec:falsification}) confirms that communication introduces strategic uncertainty without systematically shifting beliefs. Mean stated beliefs are identical under communication and pure (44.4\%), yet the communication channel opens a vector for authoritarian exploitation. The remaining sections show that this vulnerability is precisely what information control exploits.

The communication effect is also sensitive to what agents know about the coordination environment. In a robustness check (Appendix~\ref{sec:robustness}), agents are told ``you are one of 25 citizens''---providing a basis for threshold reasoning absent in the main experiment. With group-size knowledge, the communication premium reverses: communication \textit{lowers} join rates by 3.4~pp rather than raising them. When agents can reason about critical mass, messages revealing others' reluctance become more informative about the probability of reaching the coordination threshold, amplifying the deterrent effect of cautious peers. This reinforces the interpretation that communication's net effect on coordination is theoretically ambiguous: the same channel that transmits information about regime weakness also transmits evidence of others' caution.


%% ============================================================
%% 8. INFORMATION DESIGN
%% ============================================================
\section{Information Design} \label{sec:infodesign}

Part~I reported alignment using $r(J, A(\theta))$, which is positive because both the attack mass and the join fraction decrease in $\theta$. From this section onward, the information design experiments use a fixed $\theta$-grid and report $r(J, \theta)$ directly, which is \textit{negative} under equilibrium play. The sign change reflects the convention, not a behavioral reversal.

\begin{figure}[t]
  \centering
  \includegraphics[width=\columnwidth]{figures/fig07_all_designs.pdf}
  \caption{Join fraction as a function of $\theta$ under baseline, stability, instability, and public signal information designs. Baseline and stability have $N = 270$; instability and public signal have $N = 540$. Mistral Small Creative model.}
  \label{fig:all_designs}
\end{figure}

\begin{figure}[t]
  \centering
  \includegraphics[width=\columnwidth]{figures/fig08_treatment_effect.pdf}
  \caption{Treatment effect $\Delta(\theta) = \text{design join} - \text{baseline join}$ as a function of $\theta$. Negative values indicate the design suppresses coordination.}
  \label{fig:treatment_effect}
\end{figure}

Table~\ref{tab:infodesign_summary} summarizes the main results. The baseline condition produces a mean join rate of 12.4\% with a strong negative correlation between $\theta$ and join fraction ($r = -0.812$, $p < 0.001$).

\begin{result}[Information Design Shifts Coordination]
All three information designs produce measurable shifts in coordination relative to baseline.
\end{result}

The stability design sharply increases coordination: mean join rises from 12.4\% to 31.9\% ($+19.5$~pp), and the $\theta$--join relationship flattens ($r = -0.626$ vs.\ $-0.812$ at baseline). The increase is present at every $\theta$ grid point; even at $\theta = 0.80$, join rises from 0.8\% to 13.9\%. This pattern is consistent with pooling induced by ambiguity and mixed evidence: when strong-regime briefings retain substantial destabilizing cues, agents no longer sharply reduce participation in high-$\theta$ states.

The instability design reduces the mean join rate to 6.7\%, a reduction of 5.7~pp from baseline. The sharper signals allow agents to more accurately perceive regime strength, and agents with sharper information about states above $\theta^*$ are more clearly deterred from joining.

The public signal produces the largest reduction in coordination: mean join rate falls to 1.7\%, a reduction of 10.7~pp. The common news bulletin reveals that the regime is strong (since the grid is centered on $\theta^*$ and extends upward), and the overweighting of public information documented by \citet{morris2002} amplifies its effect. The correlation between $\theta$ and join fraction drops to $r = -0.537$, suggesting agents weight the public signal heavily enough to partially displace private information.

\input{tables/tab_infodesign_summary.tex}

\citet{kolotilin2022} proved that upper censorship is optimal for all priors when the sender's marginal utility is quasi-concave. I implement two censorship designs.

\begin{figure*}[t]
  \centering
  \includegraphics[width=\textwidth]{figures/fig09_censorship.pdf}
  \caption{Join fraction under upper and lower censorship vs.\ baseline. Upper censorship pools states above $\theta^*$, creating a flat join rate in the censored region.}
  \label{fig:censorship}
\end{figure*}

\begin{result}[Upper Censorship Raises Join Rates]
Upper censorship raises the mean join rate to 30.9\%, an increase of 18.5~pp over baseline. The effect is concentrated in the censored region ($\theta \geq \theta^*$): at $\theta = 0.50$, join rates rise from 12.3\% to 52.7\% ($+40.4$~pp). Below the censorship threshold, join rates are essentially unchanged.
\end{result}

The flat plateau at approximately 53\% in the censored region is clear: agents who cannot distinguish $\theta = 0.50$ from $\theta = 0.80$ behave as if the regime is moderately vulnerable. This is consistent with the pooling effect predicted by the theory.

\begin{result}[Lower Censorship Creates a Symmetric Plateau]
Lower censorship produces a mean join rate of 39.0\% ($+26.6$~pp over baseline). The correlation flips sign to $r = +0.731$, reflecting the inverted structure.
\end{result}

\begin{figure}[t]
  \centering
  \includegraphics[width=\columnwidth]{figures/fig10_infodesign_falsification.pdf}
  \caption{Falsification within information design. Scrambling collapses the $\theta$-join correlation to $r = +0.037$; flipping inverts it to $r = +0.823$.}
  \label{fig:infodesign_falsification}
\end{figure}

Under the scramble condition, the correlation between $\theta$ and join fraction collapses to $r = +0.037$ ($p = 0.55$). Under the flip condition, the correlation inverts to $r = +0.823$ ($p < 0.001$) with mean join rate soaring to 66.3\%. These results confirm that the information design effects operate through the intended signal channel.


%% ============================================================
%% 9. SURVEILLANCE
%% ============================================================
\section{Surveillance: Computational Preference Falsification} \label{sec:surveillance}

\citet{kuran1991} argued that authoritarian regimes sustain themselves partly through preference falsification. I test this by introducing a surveillance treatment in the communication game.

In the surveillance treatment, the communication prompt is augmented with a warning that communications are being monitored by regime security services. The surveillance manipulation affects only the communication phase; the decision prompt is unchanged. This isolates the chilling effect: any difference must arise from agents self-censoring their communications.

\begin{figure*}[t]
  \centering
  \includegraphics[width=\textwidth]{figures/fig12_surveillance.pdf}
  \caption{Join rates under regular communication vs.\ surveillance communication. Surveillance reduces join rates by 11.1 percentage points on average ($p < 0.001$). Results shown for three models: Mistral ($-13.4$~pp), Llama ($-8.9$~pp), and Qwen3 ($-10.9$~pp).}
  \label{fig:surveillance}
\end{figure*}

\begin{result}[Surveillance Produces a Large Chilling Effect]
In the primary model (Mistral Small Creative), surveillance reduces mean join rates from 41.1\% to 27.8\%, a difference of 13.4 percentage points ($p < 0.001$). The correlation between $\theta$ and join fraction is preserved under surveillance ($r = -0.809$ vs.\ $-0.802$), indicating that surveillance operates as a level shift rather than disrupting signal processing.
\end{result}

Surveillance contaminates the information environment with self-censored messages, pushing join rates well below the communication baseline. The effect replicates across three architectures: Mistral ($-13.4$~pp), Llama ($-8.9$~pp), and Qwen3 ($-10.9$~pp), averaging $-11.1$~pp.

The belief elicitation data confirms that this is preference falsification in the sense of \citet{kuran1991}, not belief updating. Surveillance shifts stated beliefs by only 0.7~pp relative to pure while shifting join rates by 13.4~pp---a ratio of nearly 20:1. Second-order beliefs---agents' predictions about others' join rates---are essentially unchanged by surveillance ($31.2\% \to 30.9\%$, $p = 0.59$; Section~\ref{sec:falsification}), confirming that agents do not update their beliefs about others' behavior. The belief--action correlation drops sharply under surveillance ($r = +0.73$ vs.\ $+0.84$ under pure), directly measuring the wedge that preference falsification drives between private beliefs and public actions. Communication alone already introduces strategic restraint---the belief--action correlation is lower under communication ($+0.83$) than under pure ($+0.84$)---and surveillance compounds this by further decoupling beliefs from actions across the full belief distribution. This maps onto Kuran's cascade mechanism: once agents expect others to self-censor, even authentic messages become uninformative, and the entire communication channel is poisoned.

Message content confirms the self-censorship directly. Across 15,000 communication messages and 25,000 surveillance messages, surveillance agents write shorter messages (253 vs.\ 342 characters) and systematically avoid action language: ``act'' appears in 19.0\% of communication messages but only 3.8\% under surveillance; ``collapse'' drops from 11.6\% to 0.6\%; ``together'' from 7.2\% to 0.7\%. In its place, hedged and cautious language rises: ``careful'' (1.5\% $\to$ 4.8\%), ``stable'' (1.7\% $\to$ 4.2\%), ``patience'' (0.3\% $\to$ 2.4\%). Among agents who privately decide to JOIN, only 19.0\% send action-signaling messages under surveillance, compared to 46.1\% under regular communication. Surveillance agents who intend to join write messages like \textit{``the air feels lighter\ldots keep your eyes open, but step carefully''} rather than \textit{``the walls are cracking---the machine is grinding to a halt.''} The decision is the same; the expressed sentiment is not.


%% ============================================================
%% 10. PROPAGANDA
%% ============================================================
\section{Propaganda: Information Contamination} \label{sec:propaganda}

\citet{edmond2013} modeled propaganda as the regime shifting citizens' signal distributions. I implement this by introducing propaganda agents---regime plants who transmit fixed pro-regime messages and always STAY.

\begin{figure*}[t]
  \centering
  \includegraphics[width=\textwidth]{figures/fig13_propaganda.pdf}
  \caption{Dose-response relationship between number of propaganda agents and mean join rate. Results shown for Mistral (primary) and Llama (replication). Regular communication ($k = 0$) serves as baseline.}
  \label{fig:propaganda}
\end{figure*}

\begin{result}[Propaganda Suppresses Coordination Primarily Through Mechanical Dilution]
Mean join fraction (including plants) falls from 41.1\% ($k = 0$) to 37.5\% ($k = 2$), 31.3\% ($k = 5$), and 23.3\% ($k = 10$). However, the behavioral effect on real citizens is much smaller and saturates: 41.1\% ($k = 0$), 40.7\% ($k = 2$, $-0.4$~pp), 39.1\% ($k = 5$, $-2.0$~pp), 38.8\% ($k = 10$, $-2.3$~pp).
\end{result}

Propaganda works through two channels: a \textit{mechanical} channel (plants always STAY, directly reducing attack mass) and a \textit{behavioral} channel (pro-regime messages reduce real citizens' willingness to join). The mechanical channel is approximately linear in $k$; the behavioral channel is small and saturates quickly---doubling plants from 5 to 10 produces essentially no additional behavioral effect ($-0.3$~pp). This decomposition implies sharply diminishing returns to propaganda investment: the regime's first few plants yield both mechanical and behavioral suppression, but additional plants contribute only mechanical dilution. In \citet{edmond2013}'s framework, this corresponds to a concave regime payoff in propaganda intensity---the marginal value of an additional plant falls rapidly once the behavioral channel is exhausted. At $k = 10$ (40\% of the network), real citizens' join rate has barely moved from $k = 5$ (39.1\% vs.\ 38.8\%), suggesting that citizens learn to discount pro-regime messaging after sufficient exposure.

The propaganda effect replicates with Llama 3.3 70B, which shows a behavioral effect of $-2.7$~pp at $k = 5$, confirming the qualitative pattern and the saturation across architectures.

Message content reveals the mechanism. Propaganda agents inject regime-loyal vocabulary into the communication network, and this language propagates to real agents. The fraction of messages containing ``loyal'' rises from 1.5\% at baseline to 3.5\% ($k = 2$), 6.1\% ($k = 5$), and 11.4\% ($k = 10$); ``patience'' rises from 0.3\% to 5.1\%. Meanwhile, coordination language declines: ``ready'' falls from 30.5\% to 18.5\%, ``together'' from 7.2\% to 4.2\%. Message length also shrinks (342 $\to$ 285 characters), consistent with the shorter, punchier pro-regime messages diluting the discourse. Among real agents who STAY, the fraction sending caution-coded messages rises from 24.2\% (baseline) to 38.2\% ($k = 10$)---agents are not merely responding to propaganda but \textit{echoing} it. Among those who JOIN, however, action signaling remains stable at ${\approx}\,86\%$ across all conditions. The behavioral saturation documented above thus has a linguistic correlate: propaganda shifts the discourse for agents on the margin, but agents with strong anti-regime signals continue to express and act on their beliefs regardless of the propaganda dose.

\input{tables/tab_surveillance_propaganda.tex}


%% ============================================================
%% 12. INSTRUMENT INTERACTIONS
%% ============================================================
\section{Instrument Interactions} \label{sec:interactions}

The preceding sections analyzed surveillance, censorship, and propaganda in isolation. A regime, however, deploys these instruments jointly. This section tests whether the instruments interact as substitutes (diminishing returns) or complements (super-additive suppression).

\begin{result}[Propaganda $+$ Surveillance: Approximately Additive]
When propaganda ($k = 5$) and surveillance are combined, the mean join rate among real citizens falls to 24.3\%, a reduction of 16.8~pp from the communication baseline (41.1\%). The sum of individual effects is 15.4~pp (surveillance $-13.4$~pp $+$ propaganda $-2.0$~pp), so the combined effect (16.8~pp) is approximately additive. Once surveillance has suppressed expressed dissent, propaganda adds only modest additional deterrence.
\end{result}

\begin{result}[Surveillance $\times$ Censorship: Super-Additive]
Under the information design framework, surveillance alone collapses the baseline join rate from 12.4\% to 0.9\% ($-11.5$~pp). Upper censorship without surveillance raises join rates to 30.9\% ($+18.5$~pp). But upper censorship \textit{with} surveillance produces only 3.7\%---a reduction of 27.2~pp relative to upper censorship alone. Lower censorship shows the same pattern: 39.0\% without surveillance collapses to 4.2\% with surveillance ($-34.8$~pp). The surveillance--censorship interaction is super-additive.
\end{result}

Surveillance and censorship are complements that attack different links in the coordination chain. Censorship removes the private information channel, forcing agents to rely on communication for their signals about regime strength. Surveillance then poisons that communication channel through preference falsification. With both instruments active, agents have neither private signals to trust nor authentic messages to learn from---the informational foundations of coordination are eliminated from both directions.

This complementarity is the mechanism behind the paper's headline result: upper censorship alone \textit{raises} coordination to 30.9\% (by pooling signals, it creates ambiguity that agents resolve optimistically), yet adding surveillance collapses it to 3.7\%. The regime does not need each instrument to be independently powerful. It needs the combination to close every channel through which coordination information might flow.

\input{tables/tab_surv_censor.tex}

The super-additive interaction between surveillance and censorship replicates unevenly across architectures (Table~\ref{tab:surv_censor_crossmodel}). Under communication with surveillance, Mistral and Llama~70B exhibit near-total suppression at baseline (0.9\% and 11.4\%, respectively), and upper censorship collapses both to approximately 4\% (3.7\% and 3.9\%). For these models, the combination eliminates coordination regardless of the censorship direction. GPT-OSS~120B and Qwen3~235B, by contrast, maintain substantially higher baseline join rates under surveillance (31.6\% and 33.6\%), and upper censorship reduces coordination only modestly (to 17.7\% and 32.1\%). Qwen3~235B under lower censorship actually \textit{increases} its join rate to 46.8\%, suggesting that this architecture resolves the ambiguity created by signal pooling in favor of joining. The super-additive surveillance--censorship interaction is therefore architecture-dependent: it is powerful for models that are already susceptible to the surveillance chilling effect, but substantially weaker for models that resist preference falsification at baseline.

\input{tables/tab_surv_censor_crossmodel.tex}


%% ============================================================
%% 14. CONCLUSION
%% ============================================================
\section{Conclusion} \label{sec:conclusion}

The central finding of this paper is that the information channel is a trap. Communication is the mechanism through which citizens coordinate against a regime---but it is also the vector through which the regime prevents coordination. This is not a side effect; it is structural. Any channel that transmits information about others' willingness to act also transmits \textit{uncertainty} about others' willingness to act, and that uncertainty is exploitable.

The belief elicitation data makes this concrete. Communication does not shift agents' beliefs about success ($44.4\%$ under both pure and communication), yet the channel it opens is vulnerable. Surveillance compounds this ($-13.4$~pp for Mistral, $-11.1$~pp on average) through preference falsification in the sense of \citet{kuran1991}: agents maintain their private beliefs but self-censor, generating a cascade of uninformative messages that poisons the channel for everyone. Second-order beliefs---agents' predictions about \textit{others'} join rates---are unchanged by surveillance ($31.2\% \to 30.9\%$), but actual join rates fall by 13.4~pp. Censorship eliminates the private information channel entirely, and their combination collapses coordination from 30.9\% to 3.7\%.

This pattern---surveillance contaminating communication while censorship removes the fallback---suggests that authoritarian regimes face complementarities between information control instruments, consistent with the ``informational autocrat'' framework of \citet{guriev2019}. The regime does not need to change what citizens believe. It needs only to make them uncertain about each other. Propaganda's behavioral channel is small and saturates quickly (the effect is largely exhausted by $k = 5$ plants), implying diminishing returns; the marginal authoritarian dollar is better spent on surveillance than on additional propaganda.

I do not claim that LLMs are Bayesian agents---the mechanism by which they process narrative text likely differs fundamentally from Bayesian updating. But across nine architecturally distinct models (mean $r = +0.73$, $p < 0.001$), the behavioral regularities are precisely what the global games framework predicts: monotone response to signal content, threshold-like decisions, sensitivity to information design, and preference falsification under surveillance. The consistency across architectures spanning 3B to 235B parameters suggests these regularities are not artifacts of any particular training procedure. LLMs are trained on the same informational diet---political analysis, news reporting, strategic reasoning---that shapes how citizens form beliefs about regime stability. The question is not whether they reason identically to humans, but whether the regularities are robust enough to serve as a computational laboratory for predictions that are difficult to test otherwise. The full regime change game has resisted laboratory implementation because it requires rich private signals, genuine strategic uncertainty, and large groups. LLM agents sidestep these constraints, and the same platform extends naturally to currency crises, bank runs, and other coordination games where information processing is central to behavior.


%% ============================================================
%% REFERENCES
%% ============================================================
\FloatBarrier
\begingroup
\setlength{\bibsep}{0pt}
\setlength{\itemsep}{0pt}
\scriptsize
\renewcommand{\baselinestretch}{0.93}\selectfont
\begin{thebibliography}{99}

%% ---- A ----

\bibitem[Akata et al.(2025)]{akata2025}
Akata, E., Schulz, L., Coda-Forno, J., Oh, S.~J., Bethge, M., and Schulz, E. (2025).
\newblock Playing repeated games with large language models.
\newblock \textit{Nature Human Behaviour}, 9:1380--1390.

\bibitem[Angeletos et al.(2007)]{angeletos2007a}
Angeletos, G.-M., Hellwig, C., and Pavan, A. (2007).
\newblock Dynamic global games of regime change: Learning, multiplicity, and the timing of attacks.
\newblock \textit{Econometrica}, 75(3):711--756.

\bibitem[Avoyan(2020)]{avoyan2020}
Avoyan, A. (2020).
\newblock Does cheap talk promote coordination under asymmetric information? An experimental study on global games.
\newblock \textit{Journal of Economic Behavior \& Organization}, 169:204--224.

%% ---- B ----

\bibitem[Bergemann and Morris(2016)]{bergemann2016}
Bergemann, D. and Morris, S. (2016).
\newblock Information design, {B}ayesian persuasion, and {B}ayes correlated equilibrium.
\newblock \textit{American Economic Review}, 106(5):586--591.

\bibitem[Bergemann and Morris(2019)]{bergemann2019information}
Bergemann, D. and Morris, S. (2019).
\newblock Information design: A unified perspective.
\newblock \textit{Journal of Economic Literature}, 57(1):44--95.

\bibitem[Blume and Ortmann(2007)]{blume2007}
Blume, A. and Ortmann, A. (2007).
\newblock The effects of costless pre-play communication: Experimental evidence from games with {P}areto-ranked equilibria.
\newblock \textit{Journal of Economic Theory}, 132(1):274--290.

%% ---- C ----

\bibitem[Carlini et al.(2025)]{carlini2025}
Carlini, A. et al. (2025).
\newblock Large language models show amplified cognitive biases in moral decision-making.
\newblock \textit{Proceedings of the National Academy of Sciences}, 122.

\bibitem[Carlsson and van Damme(1993)]{carlsson1993}
Carlsson, H. and van Damme, E. (1993).
\newblock Global games and equilibrium selection.
\newblock \textit{Econometrica}, 61(5):989--1018.

\bibitem[Carter and Carter(2021)]{carter2021}
Carter, E.~B. and Carter, B.~L. (2021).
\newblock Propaganda and protest in autocracies.
\newblock \textit{Journal of Conflict Resolution}, 65(5):919--949.

\bibitem[Crawford and Sobel(1982)]{crawford1982}
Crawford, V. and Sobel, J. (1982).
\newblock Strategic information transmission.
\newblock \textit{Econometrica}, 50(6):1431--1451.

%% ---- D ----

\bibitem[Diamond and Dybvig(1983)]{diamond1983}
Diamond, D.~W. and Dybvig, P.~H. (1983).
\newblock Bank runs, deposit insurance, and liquidity.
\newblock \textit{Journal of Political Economy}, 91(3):401--419.

%% ---- E ----

\bibitem[Edmond(2013)]{edmond2013}
Edmond, C. (2013).
\newblock Information manipulation, coordination, and regime change.
\newblock \textit{Review of Economic Studies}, 80(4):1422--1458.

\bibitem[Ellingsen and {\"O}stling(2010)]{ellingsen2010}
Ellingsen, T. and {\"O}stling, R. (2010).
\newblock When does communication improve coordination?
\newblock \textit{American Economic Review}, 100(4):1695--1724.

\bibitem[Enikolopov et al.(2020)]{enikolopov2020}
Enikolopov, R., Makarin, A., and Petrova, M. (2020).
\newblock Social media and protest participation: Evidence from {R}ussia.
\newblock \textit{Econometrica}, 88(4):1478--1514.

%% ---- F ----

\bibitem[Farrell and Rabin(1996)]{farrell1996}
Farrell, J. and Rabin, M. (1996).
\newblock Cheap talk.
\newblock \textit{Journal of Economic Perspectives}, 10(3):103--118.

\bibitem[Frankel et al.(2003)]{frankel03}
Frankel, D.~M., Morris, S., and Pauzner, A. (2003).
\newblock Equilibrium selection in global games with strategic complementarities.
\newblock \textit{Journal of Economic Theory}, 108(1):1--44.

%% ---- G ----

\bibitem[Gao et al.(2025)]{gao2025}
Gao, C. et al. (2025).
\newblock Validation is the central challenge for generative social simulation: A critical review of {LLM}s in agent-based modeling.
\newblock \textit{Artificial Intelligence Review}, 58.

\bibitem[Goldstein and Huang(2016)]{goldstein2016}
Goldstein, I. and Huang, C. (2016).
\newblock Bayesian persuasion in coordination games.
\newblock \textit{American Economic Review: Papers \& Proceedings}, 106(5):592--596.

\bibitem[Grossmann et al.(2025)]{grossmann2025}
Grossmann, I. et al. (2025).
\newblock Do large language models solve the problems of agent-based modeling? {A} critical review of generative social simulations.
\newblock arXiv preprint arXiv:2504.03274.

\bibitem[Guriev and Treisman(2019)]{guriev2019}
Guriev, S. and Treisman, D. (2019).
\newblock Informational autocrats.
\newblock \textit{Journal of Economic Perspectives}, 33(4):100--127.

%% ---- H ----

\bibitem[Helland et al.(2021)]{helland2021}
Helland, L., Holm, S., and Saethre, M. (2021).
\newblock Information quality and regime change: Evidence from the lab.
\newblock \textit{Journal of Economic Behavior \& Organization}, 191:538--554.

\bibitem[Heinemann et al.(2004)]{heinemann2004}
Heinemann, F., Nagel, R., and Ockenfels, P. (2004).
\newblock The theory of global games on test: Experimental analysis of coordination games with public and private information.
\newblock \textit{Econometrica}, 72(5):1583--1599.

\bibitem[Heinemann et al.(2009)]{heinemann2009}
Heinemann, F., Nagel, R., and Ockenfels, P. (2009).
\newblock Measuring strategic uncertainty in coordination games.
\newblock \textit{Review of Economic Studies}, 76(1):181--221.

\bibitem[Horton(2023)]{horton2023}
Horton, J.~J. (2023).
\newblock Large language models as simulated economic agents: What can we learn from homo silicus?
\newblock \textit{NBER Working Paper} No.~31122.

\bibitem[Huang et al.(2024)]{huang2024}
Huang, S. et al. (2024).
\newblock How ethical should {AI} be? {H}ow {AI} alignment shapes the risk preferences of {LLM}s.
\newblock arXiv preprint arXiv:2406.01168.

%% ---- I ----

\bibitem[Inostroza and Pavan(2025)]{inostroza2025}
Inostroza, N. and Pavan, A. (2025).
\newblock Adversarial coordination and public information design.
\newblock \textit{Theoretical Economics}, 20:763--813.

%% ---- J ----

%% ---- K ----

\bibitem[Kamenica and Gentzkow(2011)]{kamenica2011}
Kamenica, E. and Gentzkow, M. (2011).
\newblock Bayesian persuasion.
\newblock \textit{American Economic Review}, 101(6):2590--2615.

\bibitem[King et al.(2013)]{king2013}
King, G., Pan, J., and Roberts, M.~E. (2013).
\newblock How censorship in {C}hina allows government criticism but silences collective expression.
\newblock \textit{American Political Science Review}, 107(2):326--343.

\bibitem[Kolotilin et al.(2022)]{kolotilin2022}
Kolotilin, A., Mylovanov, T., and Zapechelnyuk, A. (2022).
\newblock Censorship as optimal persuasion.
\newblock \textit{Theoretical Economics}, 17:561--585.

\bibitem[Kuran(1991)]{kuran1991}
Kuran, T. (1991).
\newblock Now out of never: The element of surprise in the {E}ast {E}uropean revolution of 1989.
\newblock \textit{World Politics}, 44(1):7--48.

%% ---- L ----

%% ---- M ----

\bibitem[Mathevet et al.(2020)]{mathevet2020}
Mathevet, L., Perego, J., and Taneva, I. (2020).
\newblock On information design in games.
\newblock \textit{Journal of Political Economy}, 128(4):1370--1404.

\bibitem[Morris and Shin(1998)]{morris1998}
Morris, S. and Shin, H.~S. (1998).
\newblock Unique equilibrium in a model of self-fulfilling currency attacks.
\newblock \textit{American Economic Review}, 88(3):587--597.

\bibitem[Morris and Shin(2002)]{morris2002}
Morris, S. and Shin, H.~S. (2002).
\newblock Social value of public information.
\newblock \textit{American Economic Review}, 92(5):1521--1534.

\bibitem[Morris and Shin(2003)]{morris2003}
Morris, S. and Shin, H.~S. (2003).
\newblock Global games: Theory and applications.
\newblock In Dewatripont, M., Hansen, L.~P., and Turnovsky, S.~J., editors, \textit{Advances in Economics and Econometrics}, pages 56--114. Cambridge University Press.

%% ---- O ----

\bibitem[Obstfeld(1996)]{obstfeld1996}
Obstfeld, M. (1996).
\newblock Models of currency crises with self-fulfilling features.
\newblock \textit{European Economic Review}, 40(3-5):1037--1047.

%% ---- P ----

\bibitem[Penney(2016)]{penney2016}
Penney, J.~W. (2016).
\newblock Chilling effects: Online surveillance and {W}ikipedia use.
\newblock \textit{Berkeley Technology Law Journal}, 31(1):117--182.

\bibitem[Petrov et al.(2025)]{petrov2025}
Petrov, A. et al. (2025).
\newblock {LLM} strategic reasoning: Agentic study through behavioral game theory.
\newblock arXiv preprint arXiv:2502.20432.

%% ---- S ----

\bibitem[Shurchkov(2013)]{shurchkov2013}
Shurchkov, O. (2013).
\newblock Coordination and learning in dynamic global games: Experimental evidence.
\newblock \textit{Experimental Economics}, 16(2):313--334.

\bibitem[Stoycheff(2016)]{stoycheff2016}
Stoycheff, E. (2016).
\newblock Under surveillance: Examining {F}acebook's spiral of silence effects in the wake of {NSA} internet monitoring.
\newblock \textit{Journalism and Mass Communication Quarterly}, 93(2):296--311.

\bibitem[Sun et al.(2025)]{sun2025survey}
Sun, H. et al. (2025).
\newblock Game theory meets large language models: A systematic survey with taxonomy and new frontiers.
\newblock \textit{Proceedings of the International Joint Conference on Artificial Intelligence} (IJCAI).

\bibitem[Szkup and Trevino(2020)]{szkup2020}
Szkup, M. and Trevino, I. (2020).
\newblock Sentiments, strategic uncertainty, and information structures in coordination games.
\newblock \textit{Games and Economic Behavior}, 124:534--553.

\end{thebibliography}
\endgroup

\clearpage
\appendix
\renewcommand{\thefigure}{A\arabic{figure}}
\setcounter{figure}{0}
\renewcommand{\thetable}{A\arabic{table}}
\setcounter{table}{0}

\section{Robustness} \label{sec:robustness}

\begin{figure}[t]
  \centering
  \begin{subfigure}{0.49\columnwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/figA1_agent_count.pdf}
    \caption{Agent count variation ($n \in \{5, 10, 25, 50, 100\}$).}
  \end{subfigure}\hfill
  \begin{subfigure}{0.49\columnwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/figA2_network.pdf}
    \caption{Network density ($k = 4$ vs.\ $k = 8$).}
  \end{subfigure}

  \begin{subfigure}{0.98\columnwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/figA3_bandwidth.pdf}
    \caption{Bandwidth sensitivity (0.05, 0.15, 0.30).}
  \end{subfigure}
  \caption{Robustness checks for equilibrium alignment and treatment effects.}
  \label{fig:robustness}
\end{figure}

These checks show that equilibrium alignment and the qualitative information design effects are stable to agent count, network density, and the proximity bandwidth.

\paragraph{Group-size awareness.} In the main experiments, agents are told ``You do not know how many others will JOIN'' but are not told the group size, leaving them no basis for reasoning about coordination thresholds. As a robustness check, I run the pure and communication treatments with modified prompts that state ``You are one of 25 citizens deciding whether to JOIN an uprising or STAY home.'' Over 100 country--periods per treatment, the pure join rate is 0.507 (vs.\ 0.369 baseline) and the communication join rate is 0.473 (vs.\ 0.452 baseline). Monotone response to signals is preserved in both treatments. The communication premium, however, reverses: with group-size knowledge, communication \textit{lowers} join rates by 3.4~pp rather than raising them. One interpretation is that when agents know the group size, messages revealing others' reluctance become more informative about the probability of reaching critical mass, amplifying the deterrent effect of cautious peers. The level shift in the pure treatment suggests that group-size knowledge increases baseline willingness to coordinate, but the core finding---monotone signal response---is robust.

\medskip
\noindent \textit{Online appendix.} Additional supplemental material is in \texttt{online\_appendix.tex}.

\end{document}
